import random
"""This module deals with the neuron structure and functions"""
import time
from pathlib import Path
from typing import List, Optional, Union
from dataclasses import dataclass
import imageio.v2 as iio
import os
import yaml
from neurorosettes.physics import normalize_vector  # This import is causing issues
import numpy as np
from vedo import ProgressBar, merge, Cylinder, write
from vedo import Plotter  # If using vedo
from vedo import Line, Plotter as VedoPlotter 
plotter = Plotter()

class Plotter:
    def __init__(self):
        self.lines = []  # Store lines for visualization

    def addLine(self, start, end, c='red'):
        """Adds a line to the visualization from start to end."""
        self.lines.append({'start': start, 'end': end, 'color': c})
        print(f"üñçÔ∏è Added line from {start} to {end} with color {c}")
    def render(self):
        for line_data in self.lines:
            start = line_data['start']
            end = line_data['end']
            color = line_data['color']
            self.vp += Line(start, end, c=color, lw=40)  # Add line to the scene
        self.vp.show(interactive=True)

import numpy as np

def align_cells_to_lumen(self, neurons):
    """
    Forces cells into a **ring structure**, ensuring elongated axes face inward.
    """
    cluster_center = np.mean([n.cell.position for n in neurons], axis=0)

    for neuron in neurons:
        direction_to_center = normalize_vector(cluster_center - neuron.cell.position)
        if np.linalg.norm(direction_to_center) == 0:
            print(f"‚ö†Ô∏è Warning: Neuron {neuron} is at the exact cluster center, skipping normalization.")
            continue
        direction_to_center = normalize_vector(direction_to_center)

        # üîÑ **Enforce orientation & elongation in correct direction**
        neuron.cell.sphere.orientation(direction_to_center)
        neuron.cell.sphere.scale([1.8, 0.6, 1.0])  # **Stronger elongation for lumen clarity**

def get_lumen_contributors(self):
    """
    Filters out only the neurons **directly involved in lumen formation**.
    Removes excess outer cells.
    """
    cluster_center = np.mean([n.cell.position for n in self.neurons], axis=0)
    lumen_neurons = []

    for neuron in self.neurons:
        distance = np.linalg.norm(neuron.cell.position - cluster_center)

        # ‚úÖ **Only keep neurons within the correct ring distance**
        if 5.0 < distance < 15.0:  
            lumen_neurons.append(neuron)

    return lumen_neurons

def compute_clustering_coefficient(neurons):
    """Measures clustering of neurons: higher = more packed, lower = more spread."""

    if not neurons:  # üèóÔ∏è If neuron list is empty, return default clustering value
        print("‚ö†Ô∏è Warning: No neurons found. Returning default clustering coefficient = 0.")
        return 0.0  # Default clustering coefficient when no data

    # Convert neuron positions to a NumPy array
    positions = np.array([n.cell.position for n in neurons])

    # Ensure positions is a valid (N,3) shape
    if positions.shape[0] == 0 or positions.shape[1] != 3:
        print(f"‚ö†Ô∏è Warning: Expected positions to have shape (N, 3), but got {positions.shape}. Returning 0.")
        return 0.0

    # ‚úÖ Compute pairwise distances correctly
    distances = np.linalg.norm(positions[:, None, :] - positions[None, :, :], axis=2)  # (N, N) distance matrix
    
    avg_distance = np.mean(distances[distances > 0])  # Ignore self-distance
    return 1 / (1 + avg_distance)  # Normalized inverse distance

def compute_cluster_centroid(cluster):
    """Returns the centroid of a cluster of neurons."""
    positions = np.array([n.cell.position for n in cluster])
    return np.mean(positions, axis=0)

def compute_average_cluster_coefficient(clusters, repulsion_threshold=0.200, repulsion_strength=1.05, attraction_strength = 0.7):
    """
    Computes the average clustering coefficient across multiple clusters.
    
    Parameters
    ----------
    clusters : List[List[Neuron]]
        A list of clusters, where each cluster is a list of Neuron objects.

    Returns
    -------
    float
        The average clustering coefficient across all non-empty clusters.
    """
    if not clusters:
        print("‚ö†Ô∏è No clusters found. Returning 0.")
        return 0.0

    valid_coefficients = []
    for i, cluster in enumerate(clusters):
        if not cluster:
            continue
        coef = compute_clustering_coefficient(cluster)
        for i, cluster in enumerate(clusters):
            if not cluster:
                continue

            coef = compute_clustering_coefficient(cluster)

            # ‚§¥Ô∏è Redirect small or undefined clusters toward nearby lone neurons
            if len(cluster) < 3 or coef == 0.0:
                for neuron in cluster:
                    lone_neighbors = [n for c in clusters if len(c) < 3 and c != cluster for n in c
                                    if np.linalg.norm(neuron.cell.position - n.cell.position) < 15.0]
                    
                    if lone_neighbors:
                        average_target = np.mean([n.cell.position for n in lone_neighbors], axis=0)
                        direction = average_target - neuron.cell.position
                        norm = np.linalg.norm(direction)
                        if norm > 1e-3:
                            # neuron.cell.position += (direction / norm) * 0.41
                            neuron.cell.position += 0.01 * (average_target - neuron.cell.position)
                            neuron.cell.position += np.random.uniform(-0.01, 0.01, size=3)
                continue  # Skip rest of loop since cluster isn‚Äôt valid

            print(f"üìä Cluster {i+1} Clustering Coefficient: {coef:.4f}")
            valid_coefficients.append(coef)

    if not valid_coefficients:
        print("‚ö†Ô∏è No valid clusters for coefficient calculation.")
        return 0.0

    average_coef = sum(valid_coefficients) / len(valid_coefficients)
    # neuron.cell.position += np.random.uniform(-0.01, 0.01, size=3)
    print(f"üîó Average Clustering Coefficient Across Clusters: {average_coef:.4f}")
    
    # üí´ Intra-cluster attraction toward centroid
    if coef > 0.215:
        for cluster in clusters:
            centroid = compute_cluster_centroid(cluster)
            for neuron in cluster:
                to_center = centroid - neuron.cell.position
                neuron.cell.position += to_center * -attraction_strength

                for other in cluster:
                    if other is neuron:
                        continue
                    delta = neuron.cell.position - other.cell.position
                    dist = np.linalg.norm(delta)
                    if dist < 10.0 and dist > 1e-3:
                        neuron.cell.position += (delta / dist) * -0.01
    if coef >= repulsion_threshold:
        print("üí• Repulsion triggered due to high clustering coefficient.")

        # Compute cluster centroids
    centroids = [compute_cluster_centroid(cluster) for cluster in clusters]

    for i, cluster in enumerate(clusters):
        for j, other_centroid in enumerate(centroids):
            if i == j:
                continue
            direction = centroids[i] - other_centroid
            distance = np.linalg.norm(direction)
            if distance < 25.0 and distance > 0:  # Avoid divide-by-zero, was 15 before 10
                direction = direction / distance  # Normalize
                repulsion_vector = direction * repulsion_strength
                for neuron in cluster:
                    neuron.cell.position += repulsion_vector
                print(f"‚ÜîÔ∏è Applied repulsion to Cluster {i+1} away from Cluster {j+1}")
    return average_coef
# def compute_average_cluster_coefficient(clusters, repulsion_threshold=0.200, repulsion_strength=2.5, attraction_strength=0.5):
#     """
#     Computes the average clustering coefficient across multiple clusters.
#     Applies repulsion between nearby clusters if coefficient gets too high.
#     Applies gentle attraction toward each cluster's own center.
    
#     Parameters
#     ----------
#     clusters : List[List[Neuron]]
#         A list of clusters, where each cluster is a list of Neuron objects.
#     repulsion_threshold : float
#         Threshold above which inter-cluster repulsion is triggered.
#     repulsion_strength : float
#         Strength of repulsion (scales the vector).
#     attraction_strength : float
#         Strength of intra-cluster attraction.
        
#     Returns
#     -------
#     float
#         The average clustering coefficient across all non-empty clusters.
#     """
#     if not clusters:
#         print("‚ö†Ô∏è No clusters found. Returning 0.")
#         return 0.0

#     # üîü Limit to 10 largest clusters
#     clusters = sorted(clusters, key=len, reverse=True)[:10]

#     valid_coefficients = []
#     for i, cluster in enumerate(clusters):
#         if not cluster:
#             continue
#         coef = compute_clustering_coefficient(cluster)
#         print(f"üìä Cluster {i+1} Clustering Coefficient: {coef:.4f}")
#         valid_coefficients.append(coef)

#     if not valid_coefficients:
#         print("‚ö†Ô∏è No valid clusters for coefficient calculation.")
#         return 0.0

#     average_coef = sum(valid_coefficients) / len(valid_coefficients)
#     print(f"üîó Average Clustering Coefficient Across Clusters: {average_coef:.4f}")

#     # üí´ Intra-cluster attraction toward centroid
#     for cluster in clusters:
#         centroid = compute_cluster_centroid(cluster)
#         for neuron in cluster:
#             to_center = centroid - neuron.cell.position
#             neuron.cell.position += to_center * attraction_strength

#     # üí• Inter-cluster repulsion if clustering is too high
#     if average_coef >= repulsion_threshold:
#         print("üí• Repulsion triggered due to high clustering coefficient.")

#         centroids = [compute_cluster_centroid(cluster) for cluster in clusters]

#         for i, cluster in enumerate(clusters):
#             for j, other_centroid in enumerate(centroids):
#                 if i == j:
#                     continue
#                 direction = centroids[i] - other_centroid
#                 distance = np.linalg.norm(direction)
#                 if distance < 20.0 and distance > 1e-3:
#                     repulsion_vector = (direction / distance) * repulsion_strength
#                     for neuron in cluster:
#                         neuron.cell.position += repulsion_vector
#                     print(f"‚ÜîÔ∏è Applied repulsion to Cluster {i+1} away from Cluster {j+1}")

#     return average_coef

def compute_nearest_neighbor_variance(neurons):
    """Measures uniformity of spacing: higher = more uneven spacing, lower = ideal spacing."""

    if not neurons:  # üèóÔ∏è If neuron list is empty, return default variance
        print("‚ö†Ô∏è Warning: No neurons found. Returning default nearest neighbor variance = 0.")
        return 0.0  # Default variance when no data

    positions = np.array([n.cell.position for n in neurons])

    if positions.shape[0] == 0 or positions.shape[1] != 3:
        print(f"‚ö†Ô∏è Warning: Expected positions to have shape (N, 3), but got {positions.shape}. Returning 0.")
        return 0.0

    # ‚úÖ Compute pairwise distances correctly
    distances = np.linalg.norm(positions[:, None, :] - positions[None, :, :], axis=2)  # (N, N) distance matrix

    nearest_distances = np.sort(distances, axis=1)[:, 1]  # Exclude self-distance
    return np.var(nearest_distances)  # Variance of spacing

def compute_orientation_entropy(neurons):
    """Measures randomness in cell orientation: lower entropy = better polarization."""
    orientations = np.array([n.outgrowth_axis for n in neurons])
    dot_products = np.dot(orientations, orientations.T)
    alignment_scores = np.mean(dot_products)
    entropy = -alignment_scores * np.log2(alignment_scores + 1e-9)  # Avoid log(0)
    return entropy

def compute_aspect_ratio(neurons):
    """Measures cell elongation."""
    
    if not neurons:  # üèóÔ∏è Handle empty neuron lists
        print("‚ö†Ô∏è Warning: No neurons found. Returning default aspect ratio = 1.0")
        return 1.0  # Default aspect ratio (round cells)

    scales = np.array([n.cell.sphere.scale() for n in neurons])

    # ‚úÖ Ensure scales is at least 2D
    if scales.ndim == 1:
        print(f"‚ö†Ô∏è Warning: Expected (N, 3) array, but got {scales.shape}. Reshaping...")
        scales = scales.reshape(-1, 3)  # Convert (N,) to (N,3)

    return np.mean(scales[:, 0] / scales[:, 1])  # X-axis elongation relative to Y

def compute_radial_symmetry(neurons):
    """Measures how well cells form a circular rosette around a lumen."""
    
    if not neurons:  # üèóÔ∏è Handle empty neuron lists
        print("‚ö†Ô∏è Warning: No neurons found. Returning default radial symmetry = 0.")
        return 0.0  

    positions = np.array([n.cell.position for n in neurons])

    # ‚úÖ Ensure positions is at least 2D (N,3)
    if positions.ndim == 1:
        print(f"‚ö†Ô∏è Warning: Expected (N, 3) array, but got {positions.shape}. Reshaping...")
        positions = positions.reshape(-1, 3)  # Convert (N,) to (N,3)

    center = np.mean(positions, axis=0)  # Compute cluster center
    distances = np.linalg.norm(positions - center, axis=1)  # Compute radial distances

    return np.std(distances)  # Lower std means better symmetry

# from neurorosettes.config import ConfigParser
# from neurorosettes.clocks import ClocksFactory
# from neurorosettes.physics import (
#     ContactFactory,
#     PotentialsFactory,
#     SimpleFactory,
#     get_cylinder_intersection,
# )
# from neurorosettes.subcellular import CellBody, Neurite, ObjectFactory
# from neurorosettes.neurons import Neuron, NeuronFactory
# from neurorosettes.utilities import Animator, get_random_unit_vector
# from neurorosettes.grid import UniformGrid, CellDensityCheck

from config import ConfigParser
from clocks import ClocksFactory
from physics import (
    ContactFactory,
    PotentialsFactory,
    SimpleFactory,
    get_cylinder_intersection,
)
from subcellular import CellBody, Neurite, ObjectFactory
from neurons import Neuron, NeuronFactory
from utilities import Animator, get_random_unit_vector
from grid import UniformGrid, CellDensityCheck


def ccw(A, B, C):
    return (C[1] - A[1]) * (B[0] - A[0]) > (B[1] - A[1]) * (C[0] - A[0])


# Return true if line segments AB and CD intersect
def intersect(A, B, C, D):
    return ccw(A, C, D) != ccw(B, C, D) and ccw(A, B, C) != ccw(A, B, D)


@dataclass
class Timer:
    """Class to store the simulation time data."""

    total_time: float
    """The total time of a simulation (in minutes)."""
    step: float = 0.3
    """The time between simulation points (in minutes)."""
    current_time: float = 0.0
    """The current time point of the simulation."""

    def get_progress_bar(self) -> ProgressBar:
        """Returns a progress bar with the simulation time"""
        return ProgressBar(0, self.total_time / self.step, c="r")


class SimulationContainer:
    """
    Class that represents the environment where neurons exist.

    Parameters
    ----------
    grid
        The grid where simulation objects will be stored,
        to improve neighbor interactions.
    simulation_2d
        If the simulation is 2D or 3D.
    neuron_factory
        The factory object to be used to create new neurons.
    contact_factory
        The factory object to be used to create interactions.
    drag_coefficient
        The drag coefficient of the extracellular space.
    density_check
        Optional contact inhibition function to inhibit proliferation
        when the cell density is too high.
    """
    def __init__(
        self,
        grid: UniformGrid,
        simulation_2d: bool,
        neuron_factory: NeuronFactory,
        contact_factory: ContactFactory,
        timer: Timer,
        drag_coefficient: float = 10.0,
        density_check: Optional[CellDensityCheck] = None,
        plotter=None
    ) -> None:
        # Existing initialization code
        self.dynamic_proliferation_rate = 1.5
        self.timer = timer
        self.grid = grid
        self.simulation_2d = simulation_2d
        self.sphere_int = contact_factory.get_sphere_sphere_interactions()
        self.sphere_cylinder_int = contact_factory.get_sphere_cylinder_interactions()
        self.cylinder_int = contact_factory.get_cylinder_cylinder_interactions()
        self.neuron_factory = neuron_factory
        self.contact_factory = contact_factory
        self.object_factory = self.neuron_factory.objects_factory
        self.drag_coefficient = drag_coefficient
        self.density_check = density_check
        self.animator = Animator()
        self.neurons = []
        self.rosette_formed = False  # Add a flag to track rosette formation
        self.indicator_color = "blue"  # Initial color for indicator
        self.locked_clusters = set()
        self.clustering_complete = False
        self.constriction_complete = False
        self.polarization_complete = False  # Tracks if clustering phase has completed
        self.constriction_complete = False
        self.polarization_complete = False
        self.elongation_complete = False 
        self.lumenation_complete = False # üõ†Ô∏è Initialize elongation tracking!
        self.plotter = plotter
        

        if self.simulation_2d:
            self.animator.add_grid(
                self.grid.representation_grid_values,
                self.grid.representation_grid_values,
            )
    def remove_neurites(self):
            """
            Removes all neurites from neurons and clears their visual representation.
            """
            for neuron in self.neurons:
                neuron.neurites.clear()  # Remove neurites from neuron structure

            # Remove all springs visually (assuming self.springs stores neurite representations)
            for spring in self.animator.springs:
                self.animator.plotter.remove(spring)

            # Clear the stored springs list to prevent further references
            self.animator.springs.clear()

            print("Neurites removed.")  # Debugging
            
  
    def apply_clustering_force(self, clustering_strength=0.01, attraction_probability=0.3, resistance_probability=0.23):
            """
            Moves neurons toward the cluster center with a **chance** of getting pulled in.
            
            Parameters:
            - clustering_strength: How strongly neurons move toward the center (default: slow pull).
            - attraction_probability: Chance that a neuron **starts moving** toward the cluster.
            - resistance_probability: Chance a neuron **actively resists** and stays put.
            """
            if len(self.neurons) < 2:
                return  # No clustering possible with one neuron

            cluster_center = np.mean([n.cell.position for n in self.neurons], axis=0)  # Compute cluster center

            for neuron in self.neurons:
                if np.random.rand() < resistance_probability:  # Some neurons **actively resist** clustering
                    continue  

                if np.random.rand() < attraction_probability:  # Some neurons get pulled in
                    direction_to_center = cluster_center - neuron.cell.position
                    neuron.cell.position += direction_to_center * clustering_strength  # Controlled gradual movement
                    neuron.cell.sphere.color("blue")  # Keep them **blue** while moving
    def apply_post_polarization_constriction(self, constriction_strength=0.02, attraction_probability=0.5, resistance_probability=0.15):
        """
        Gradually pulls neurons **tighter into their respective clusters** after polarization.

        - `constriction_strength`: How strongly neurons are pulled in (default: moderate pull).
        - `attraction_probability`: Chance that a neuron **starts moving** toward the cluster center.
        - `resistance_probability`: Chance a neuron **resists** and stays put.
        """

        # Identify cluster centers
        cluster_centers = self.identify_cluster_centers()

        if not cluster_centers:
            print("‚ö†Ô∏è No valid clusters detected for constriction.")
            return

        for neuron in self.neurons:
            # Determine which cluster it belongs to
            distances = [np.linalg.norm(neuron.cell.position - center) for center in cluster_centers]
            cluster_index = np.argmin(distances)
            cluster_center = cluster_centers[cluster_index]

            # Some neurons resist the constriction
            if np.random.rand() < resistance_probability:
                continue  

            # Some neurons get pulled toward the cluster center
            if np.random.rand() < attraction_probability:
                direction_to_center = cluster_center - neuron.cell.position
                neuron.cell.position += direction_to_center * constriction_strength  # Controlled movement
                neuron.cell.sphere.color("blue")  # Keep them **blue** while moving

        print("üîÑ Post-polarization constriction applied: Clusters tightening.")

    def assign_vertex_colors(self, sphere, apical_vector, apical_color, basal_color):
        """
        Manually assigns vertex colors based on their orientation relative to apical_vector.
        
        ‚úÖ Ensures **apical side is red** and **basal side is blue**.
        """
        vertices = sphere.points()  # Get all vertex positions
        colors = []
        print(f"üß¨ Vertex count: {len(vertices)} | Assigned color count: {len(colors)}")
        center = np.mean(vertices, axis=0)  # Manually compute the center
        

        for vertex in vertices:
            # Compute dot product to check alignment with apical vector
            alignment = np.dot(normalize_vector(vertex - center), apical_vector)

            # Assign color: Red if close to apical direction, Blue otherwise
            if alignment > 0:
                colors.append(apical_color)  # Apical (red)
            else:
                colors.append(basal_color)  # Basal (blue)

        print(f"üß¨ Vertex count: {len(vertices)} | Assigned color count: {len(colors)}")
        return colors
        
    def apply_density_aware_clustering_force(self, clustering_strength=0.5, base_attraction_prob=0.19, resistance_probability=0.15):
        """
        Moves neurons toward denser local regions to form emergent clusters from initial positions.

        Parameters:
        - clustering_strength: Base strength for attraction movement.
        - base_attraction_prob: Starting probability to get attracted to a dense region.
        - resistance_probability: Probability a neuron resists movement.
        """
        if len(self.neurons) < 2:
            return

        # Compute local densities using a simple proximity-based heuristic
        neighbor_radius = 10.0  # Adjustable radius to define local density
        density_map = {}
        for neuron in self.neurons:
            close_neighbors = [n for n in self.neurons if np.linalg.norm(neuron.cell.position - n.cell.position) < neighbor_radius]
            density_map[neuron] = len(close_neighbors)

        max_density = max(density_map.values()) if density_map else 1

        for neuron in self.neurons:
            if np.random.rand() < resistance_probability:
                continue

            # Higher attraction probability in denser regions
            local_density = density_map[neuron]
            attraction_prob = base_attraction_prob + (local_density / max_density) ** 2 * 0.5  # boost probability

            if np.random.rand() < attraction_prob:
                # Move neuron toward local center of density
                neighbors = [n for n in self.neurons if np.linalg.norm(neuron.cell.position - n.cell.position) < neighbor_radius]
                if not neighbors:
                    continue
                local_center = np.mean([n.cell.position for n in neighbors], axis=0)
                direction = local_center - neuron.cell.position
                neuron.cell.position += -direction * clustering_strength
                # neuron.cell.sphere.color("blue")
                
    def remove_outlier_neurons(self, removal_threshold=7.5, min_cluster_size=10, spread_distance=75.0):
        """
        Keeps the three largest clusters and removes all others.
        Then spreads the top 3 clusters apart in space for clarity.

        - `removal_threshold`: Optional legacy param (not used).
        - `min_cluster_size`: Minimum size for a cluster to be retained.
        - `spread_distance`: Distance between each cluster's new center.
        """
        if len(self.neurons) < 2:
            return

        clusters = self.find_clusters(distance_threshold=4.5)

        if not clusters:
            return

        # Sort clusters by descending size
        sorted_clusters = sorted(clusters, key=len, reverse=True)

        # Take only the top 3 that meet min size
        clusters_to_keep = sorted_clusters[:3]

        if not clusters_to_keep:
            print("üö® No clusters large enough to retain.")
            return

        # Flatten kept neurons
        neurons_to_keep = [n for cluster in clusters_to_keep for n in cluster]
        neurons_to_remove = [n for n in self.neurons if n not in neurons_to_keep]

        print(f"\nüîç Found {len(clusters)} clusters.")
        for i, c in enumerate(clusters_to_keep):
            print(f"‚úÖ Cluster {i+1} size: {len(c)}")
        print(f"üóë Removing {len(neurons_to_remove)} neurons outside top 3 clusters.")

        # Hide neurons that are being removed
        for neuron in neurons_to_remove:
            if hasattr(neuron.cell, "sphere"):
                neuron.cell.sphere.alpha(0)

        # üåê Spread the top 3 clusters apart
        cluster_offsets = [
            np.array([-spread_distance, 0, 0]),
            np.array([spread_distance, 0, 0]),
            np.array([0, spread_distance, 0])
        ]
        for cluster_index, cluster in enumerate(clusters_to_keep):
            offset = cluster_offsets[cluster_index]
            cluster_center = np.mean([n.cell.position for n in cluster], axis=0)
            
            for neuron in cluster:
                if not hasattr(neuron, "spread_target"):
                    neuron.spread_target = neuron.cell.position + (offset - cluster_center)

        # for cluster_index, cluster in enumerate(clusters_to_keep):
        #     offset = cluster_offsets[cluster_index]   
        #     cluster_center = np.mean([n.cell.position for n in cluster], axis=0)

        #     for neuron in cluster:
        #         neuron.cell.position += (offset - cluster_center)

        # ‚úÖ Finalize the neuron list
        self.neurons = neurons_to_keep
    def apply_cluster_spread(self, spread_strength=0.61):
        """
        Gradually nudges neurons toward their assigned cluster offset.
        Call this repeatedly after remove_outlier_neurons().
        """
        spreading_done = True

        for neuron in self.neurons:
            if hasattr(neuron, "spread_target"):
                direction = neuron.spread_target - neuron.cell.position
                distance = np.linalg.norm(direction)

                if distance > 0.5:  # Still far from target
                    neuron.cell.position += direction * spread_strength
                    spreading_done = False

        if spreading_done:
            self.clusters_spread = True  # You can use this flag to stop further spreading
#9:43 PM - 3 clusters
    # def remove_outlier_neurons(self, removal_threshold=7.5, min_cluster_size=10):
    #     """
    #     Keeps the **three largest clusters** and removes all other neurons.

    #     Parameters:
    #     - removal_threshold: Optional, not used in this version.
    #     - min_cluster_size: Clusters smaller than this will be ignored entirely.
    #     """
    #     if len(self.neurons) < 2:
    #         return

    #     # üîπ Find all clusters using a stricter distance threshold
    #     clusters = self.find_clusters(distance_threshold=4.5)

    #     if not clusters:
    #         return

    #     # üîç Sort clusters by size (largest first)
    #     sorted_clusters = sorted(clusters, key=len, reverse=True)

    #     # ‚úÖ Keep the largest three clusters (if they meet the minimum size)
    #     clusters_to_keep = [cluster for cluster in sorted_clusters[:3] if len(cluster) >= min_cluster_size]

    #     if not clusters_to_keep:
    #         print("üö® No clusters large enough to retain.")
    #         return

    #     # üîó Flatten clusters_to_keep into one list
    #     neurons_to_keep = [n for cluster in clusters_to_keep for n in cluster]
    #     neurons_to_remove = [n for n in self.neurons if n not in neurons_to_keep]

    #     print(f"\nüîç Found {len(clusters)} clusters.")
    #     print(f"‚úÖ Keeping top 3 clusters with total {len(neurons_to_keep)} neurons.")
    #     print(f"üóë Removing {len(neurons_to_remove)} neurons outside the top clusters.")

    #     for neuron in neurons_to_remove:
    #         if hasattr(neuron.cell, "sphere"):
    #             neuron.cell.sphere.alpha(0)  # Hide the neuron
    #             # Optionally: self.animator.plotter.remove(neuron.cell.sphere)

    #     # ‚úÖ Update self.neurons to only include those we're keeping
    #     self.neurons = neurons_to_keep


# 9:36 PM: One cluster
    # def remove_outlier_neurons(self, removal_threshold=7.5, min_cluster_size=38):
    #     """
    #     Removes neurons that are too far from the **largest, densest cluster**.

    #     - `removal_threshold`: Distance beyond which neurons are **deleted**.
    #     - `min_cluster_size`: Minimum neurons required to **retain a cluster**.
    #     """
    #     if len(self.neurons) < 2:
    #         return  # No need to check if only one neuron exists

    #     # **Find all clusters**
    #     clusters = self.find_clusters(distance_threshold=4.5)  # üîπ Stricter clustering check

    #     if not clusters:
    #         return  # No valid clusters found, skip processing

    #     # **Find the most populated cluster**
    #     largest_cluster = max(clusters, key=len)

    #     # **Only keep the largest cluster if it's big enough**
    #     if len(largest_cluster) < min_cluster_size:
    #         print(f"üö® Largest cluster is too small ({len(largest_cluster)} neurons). No removal applied.")
    #         return  

    #     cluster_center = np.mean([n.cell.position for n in largest_cluster], axis=0)

    #     # **Identify neurons that are too far from the core cluster**
    #     neurons_to_remove = [n for n in self.neurons if n not in largest_cluster]
    #     # for neuron in self.neurons:
    #     #     distance_to_center = np.linalg.norm(neuron.cell.position - cluster_center)

    #     #     # üö® **Remove neuron if it's NOT in the largest cluster OR is too far**
    #     #     if neuron not in largest_cluster or distance_to_center > removal_threshold:
    #     #         neurons_to_remove.append(neuron)

    #     print(f"\nüîç Found {len(clusters)} clusters. Keeping largest ({len(largest_cluster)} neurons).")
    #     print(f"üóë Removing {len(neurons_to_remove)} neurons outside the main cluster.")

    #     # **Remove neurons properly**
    #     for neuron in neurons_to_remove:
    #         if hasattr(neuron.cell, "sphere"):
    #             # ‚úÖ Make the neuron invisible BEFORE removal (prevents errors)
    #             neuron.cell.sphere.alpha(0)

    #             # ‚úÖ Fully remove from visualization
    #             # self.animator.plotter.remove(neuron.cell.sphere)

    #     # ‚úÖ **Filter out removed neurons instead of `remove()`**
    #     self.neurons = largest_cluster



    def compact_clusters_spherically(self, attraction_strength=0.2, iterations=20):
        """
        Adjusts neuron positions to make clusters more spherical and compact before polarization.

        - `attraction_strength`: How strongly neurons are pulled toward their cluster centers.
        - `iterations`: Number of cycles to refine the cluster shape.
        """
        clusters = self.find_clusters(distance_threshold=4.5)
        sorted_clusters = sorted(clusters, key=len, reverse=True)
        clusters_to_keep = sorted_clusters[:3]  # Keep only the 3 largest clusters

        if len(clusters_to_keep) < 3:
            print("üö® Warning: Less than 3 clusters detected!")

        # Compute initial cluster centers
        cluster_centers = [np.mean([n.cell.position for n in cluster], axis=0) for cluster in clusters_to_keep]

        for _ in range(iterations):
            for cluster_idx, cluster in enumerate(clusters_to_keep):
                cluster_center = cluster_centers[cluster_idx]

                for neuron in cluster:
                    # Compute direction from neuron to cluster center
                    direction_to_center = cluster_center - neuron.cell.position
                    distance = np.linalg.norm(direction_to_center)

                    if distance > 0:  # Avoid division by zero
                        # Normalize the direction and apply force toward center
                        force = (direction_to_center / distance) * attraction_strength
                        neuron.cell.position += force  # Apply movement

                        # Optional: Add slight random jitter to avoid artificial grid-like packing
                        neuron.cell.position += np.random.uniform(-0.05, 0.05, size=3)

            # Recalculate cluster centers after each iteration
            cluster_centers = [np.mean([n.cell.position for n in cluster], axis=0) for cluster in clusters_to_keep]

        print("‚úÖ Clusters refined: More compact and spherical.")

    def apply_constriction(self, removal_threshold=5.0, min_cluster_size=10):
        """
        Removes neurons that are too far from the largest, densest cluster.
        
        - `removal_threshold`: Distance beyond which neurons are **deleted** from the simulation.
        - `min_cluster_size`: The **minimum** number of neurons needed for a cluster to be kept.
        """
        if len(self.neurons) < 2:
            return  # No need to check if only one neuron exists

        # **Find all clusters**
        clusters = self.find_clusters(distance_threshold=4.0)  # üîπ Make clustering stricter

        if not clusters:
            return  # No valid clusters found, skip processing

        # **Find the most populated cluster**
        largest_cluster = max(clusters, key=len)

        # **Only keep the largest cluster if it's big enough**
        if len(largest_cluster) < min_cluster_size:
            print(f"üö® Largest cluster is too small ({len(largest_cluster)} neurons). No constriction applied.")
            return  

        cluster_center = np.mean([n.cell.position for n in largest_cluster], axis=0)

        # **Identify neurons that are too far from the core cluster**
        neurons_to_remove = []
        for neuron in self.neurons:
            distance_to_center = np.linalg.norm(neuron.cell.position - cluster_center)

            # üö® **Mark neuron for removal if it's far from the core**
            if neuron not in largest_cluster or distance_to_center > removal_threshold:
                neurons_to_remove.append(neuron)

        print(f"\nüîç Found {len(clusters)} clusters. Keeping largest ({len(largest_cluster)} neurons).")
        print(f"üóë Removing {len(neurons_to_remove)} neurons that are too far.")

        # **Remove neurons outside the core cluster**
        for neuron in neurons_to_remove:
            self.neurons.remove(neuron)
            if hasattr(neuron.cell.sphere, "alpha"):  
                neuron.cell.sphere.alpha(0)  # Hide instead of deleting (avoids crashes)
            if hasattr(neuron.cell.sphere, "visible"):
                neuron.cell.sphere.visible(False)  
        
    def apply_sheet_formation(self):
        """Forces all neurons into a cohesive monolayer with minimal vertical displacement."""
        avg_z = np.mean([n.cell.position[2] for n in self.neurons])  # Find central sheet plane
        for neuron in self.neurons:
            neuron.cell.position[2] = avg_z  # Align all cells to same Z-plane
            neuron.cell.sphere.color("yellow")  # Mark sheet formation
    def apply_lateral_stretching(self):
        """Stretches the sheet by encouraging lateral expansion."""
        centroid = np.mean([n.cell.position for n in self.neurons], axis=0)
        for neuron in self.neurons:
            stretch_vector = normalize_vector(neuron.cell.position - centroid) * 0.02  # Weak expansion force
            neuron.cell.position += stretch_vector  
            neuron.cell.sphere.scale([1.2, 1.0, 1.0])  # Slight X-axis elongation
    def apply_polarity_establishment(self, spread_factor=-0.12, alignment_duration=2.0):
        """
        Establishes apical-basal polarity for each of the three clusters:
        ‚úÖ Each cluster forms a **uniform sphere** around its center.
        ‚úÖ Apical (red) side faces inward toward the cluster center.
        ‚úÖ Basal (blue) side faces outward.
        ‚úÖ Gradual orientation correction over `alignment_duration` time.
        ‚úÖ Adds slight outward spread for clarity.
        """
        current_time = self.timer.current_time

        if not hasattr(self, "polarization_start_time"):
            self.polarization_start_time = current_time  # Set the start time

        elapsed_time = current_time - self.polarization_start_time
        alignment_progress = min(elapsed_time / alignment_duration, 1.0)  # Normalize progress (0 ‚Üí 1)

        print(f"\nüî¥ Polarization Debug: Time {current_time:.2f}s, Progress: {alignment_progress:.2%}")

        # **Find the three largest clusters**
        clusters = self.find_clusters(distance_threshold=4.5)
        sorted_clusters = clusters
        clusters_to_keep = sorted_clusters
        # sorted_clusters = sorted(clusters, key=len, reverse=True)
        # clusters_to_keep = sorted_clusters[:3]  # Keep the three largest

        if len(clusters_to_keep) < 3:
            print(f"üö® Warning: Less than 3 clusters found! Only {len(clusters_to_keep)} will be polarized.")

        # **Compute the center of each cluster**
        cluster_centers = [np.mean([n.cell.position for n in cluster], axis=0) for cluster in clusters_to_keep]
        
        for i, center in enumerate(cluster_centers):
            print(f"üü¢ Cluster {i+1} center: {center}")

        # **Assign neurons to their respective clusters**
        neuron_cluster_map = {}
        for i, cluster in enumerate(clusters_to_keep):
            for neuron in cluster:
                neuron_cluster_map[neuron] = i  # Store which cluster this neuron belongs to

        for neuron in self.neurons:
            if neuron not in neuron_cluster_map:
                continue  # Skip neurons that are not in the top 3 clusters

            cluster_idx = neuron_cluster_map[neuron]
            cluster_center = cluster_centers[cluster_idx]

            if not hasattr(neuron, "polarized"):
                neuron.polarized = False  # Track the state of each neuron

            # üîÑ **Ensure uniform sphere distribution around cluster center**
            direction_to_center = normalize_vector(cluster_center - neuron.cell.position)
            print(f"üîÑ Neuron at {neuron.cell.position} ‚Üí Direction to cluster {cluster_idx+1}: {direction_to_center}")

            neuron.cell.position += -direction_to_center * spread_factor  # Slight outward spread
           
            apical_axis = normalize_vector(cluster_center - neuron.cell.position)
            # Assign red/blue based on that axis
            colors = self.assign_vertex_colors(neuron.cell.sphere, apical_axis, (1, 0, 0), (0, 0, 1))
            neuron.cell.sphere.pointColors(colors, alpha=1)
            print(f"‚úÖ Applied {len(colors)} vertex colors to sphere")

            # üî¥ Draw a red line showing the apical direction
            apical_tip = neuron.cell.position + apical_axis * 3
            if not hasattr(self, "plotter"):
                raise AttributeError("üö® Error: self.plotter is not defined in SimulationContainer!")

            if not hasattr(self.plotter, "addLine"):
                raise AttributeError("üö® Error: self.plotter does not have an addLine method!")

            print(f"üß© Debug: Type of self.plotter ‚Üí {type(self.plotter)}")
            if not hasattr(self.plotter, "addLine"):
                raise AttributeError(f"üö® Error: self.plotter exists but does not have an addLine method! Type: {type(self.plotter)}")

            # self.plotter.addLine(neuron.cell.position, apical_tip, c='red')

            # ‚úÖ Debug
            print(f"üé® Neuron {neuron} - Forced Apical Axis: {apical_axis}")


            # üéØ **Gradually Align Apical Side Inward**
            adjusted_direction = (
                (1 - alignment_progress) * neuron.cell.sphere.orientation() +
                alignment_progress * direction_to_center
            )
            neuron.cell.sphere.orientation(adjusted_direction)

            print(f"üìè Neuron {neuron} - Adjusted Orientation: {adjusted_direction}")

            # ‚úÖ **Final Polarity Lock-in**
            if alignment_progress >= 1.0:
                neuron.polarized = True  # Lock polarization
                self.polarization_complete = True  # Mark simulation phase complete
            if self.polarization_complete:
                # self.plotter.render()
                print(f"‚úÖ Polarization complete: {self.polarization_complete}")
    def spread_apart_clusters(self, spread_distance=30.0, spread_duration=2.0, spread_speed=0.05):
        """
        Gradually spreads the top 3 clusters apart into a triangle to prevent interference during lumenation.

        Parameters
        ----------
        spread_distance : float
            How far apart to move the clusters.
        spread_duration : float
            Total time (seconds) over which to complete the spreading.
        spread_speed : float
            Scale factor controlling how fast neurons move per frame.
        """
        current_time = self.timer.current_time

        # Initialize start time if not already set
        if not hasattr(self, "cluster_spread_start_time"):
            self.cluster_spread_start_time = current_time

        elapsed_time = current_time - self.cluster_spread_start_time
        progress = min(elapsed_time / spread_duration, 1.0)  # Clamped between 0 and 1

        clusters = self.find_clusters(distance_threshold=4.5)
        if not clusters:
            print("‚ö†Ô∏è No clusters found")
            return

        num_clusters = len(clusters)

        # Arrange clusters in a circle for even spreading
        cluster_targets = []
        for i in range(num_clusters):
            angle = (2 * np.pi * i) / num_clusters
            x = spread_distance * np.cos(angle)
            y = spread_distance * np.sin(angle)
            cluster_targets.append(np.array([x, y, 0]))

        cluster_centers = [np.mean([n.cell.position for n in cluster], axis=0) for cluster in clusters]

        print(f"\nüì¶ Spreading Clusters: Progress = {progress:.1%}")
        for idx, (cluster, current_center, target_center) in enumerate(zip(clusters, cluster_centers, cluster_targets)):
            shift_vector = (target_center - current_center) * spread_speed * progress
            for neuron in cluster:
                neuron.cell.position += shift_vector

    def project_clusters_onto_plane_gradually(self, projection_duration=2.0):
        """
        Gradually projects each cluster's neurons onto a local plane orthogonal to
        the cluster's principal axis, and scales each cell to 0.8 x 0.8 x 2.0 
        relative to that cluster's orientation.

        Parameters
        ----------
        projection_duration : float
            Time (in seconds) over which the projection completes.
        """
        current_time = self.timer.current_time

        if not hasattr(self, "projection_start_time"):
            self.projection_start_time = current_time

        elapsed = current_time - self.projection_start_time
        progress = min(elapsed / projection_duration, 1.0)

        clusters = self.find_clusters(distance_threshold=4.5)
        if not clusters:
            print("‚ö†Ô∏è No clusters found.")
            return

        print(f"\nüì¶ Projecting {len(clusters)} clusters to their local planes...")
        print(f"‚è±Ô∏è Elapsed: {elapsed:.2f}s / {projection_duration:.2f}s ‚Üí Progress: {progress:.2%}")

        for c_idx, cluster in enumerate(clusters):
            if len(cluster) < 3:
                continue  # skip tiny clusters

            # Step 1: Compute PCA manually
            positions = np.array([n.cell.position for n in cluster])
            cluster_center = np.mean(positions, axis=0)
            centered = positions - cluster_center

            cov = np.cov(centered, rowvar=False)
            eigvals, eigvecs = np.linalg.eigh(cov)  # eigvecs: columns

            sorted_indices = np.argsort(eigvals)[::-1]
            eigvecs = eigvecs[:, sorted_indices]
            R = eigvecs  # local ‚Üí world axes

            print(f"\nüîπ Cluster {c_idx+1}:")
            print(f"   - Center: {np.round(cluster_center, 2)}")
            print(f"   - Main axis (1st PC): {np.round(R[:,0], 3)}")

            # Step 2: Loop over neurons and project + scale
            for i, neuron in enumerate(cluster):
                pos = neuron.cell.position.copy()

                if not hasattr(neuron, "original_position_for_projection"):
                    neuron.original_position_for_projection = pos.copy()

                original_pos = neuron.original_position_for_projection.copy()
                rel_vector = original_pos - cluster_center

                # Projection: remove component along first principal axis
                projection_length = np.dot(rel_vector, R[:,0])
                projection_vector = projection_length * R[:,0]
                target_pos = original_pos - projection_vector

                interpolated_pos = (1 - progress) * original_pos + progress * target_pos
                neuron.cell.position = interpolated_pos

                # Step 3: Scale gradually toward 0.8 √ó 0.8 √ó 2.0 in cluster-local frame
                target_local_scale = np.array([0.8, 0.8, 2.0])
                S = np.diag(target_local_scale)
                world_scale_matrix = R @ S @ R.T

                interpolated_scale_matrix = np.eye(3) + progress * (world_scale_matrix - np.eye(3))
                scale_vector = interpolated_scale_matrix @ np.ones(3)

                neuron.cell.sphere.scale(scale_vector)

                # üß† Debug info
                print(f"   üß¨ Neuron {i+1}")
                print(f"      - Original Pos:   {np.round(original_pos, 2)}")
                print(f"      - Projected Pos:  {np.round(target_pos, 2)}")
                print(f"      - Final Pos:      {np.round(interpolated_pos, 2)}")
                print(f"      - Scale Vector:   {np.round(scale_vector, 3)}")


    def split_elongated_cells(self, elongation_threshold=2.0, split_distance=3.5):
        """
        Splits neurons that are sufficiently elongated by duplicating them along the apical-basal axis.
        Doubles the number of cells post-elongation.

        Parameters:
        - elongation_threshold: Minimum Z-axis scale to qualify for division.
        - split_distance: Distance between the original and new cell along the apical-basal axis.
        """
        new_neurons = []

        # Find the three largest clusters again to calculate consistent centers
        clusters = self.find_clusters(distance_threshold=4.5)
        sorted_clusters = sorted(clusters, key=len, reverse=True)
        clusters_to_keep = sorted_clusters[:3]
        cluster_centers = [np.mean([n.cell.position for n in cluster], axis=0) for cluster in clusters_to_keep]

        # Map neurons to cluster index (assumes similar clustering from polarization)
        neuron_cluster_map = {}
        for i, cluster in enumerate(clusters_to_keep):
            for neuron in cluster:
                neuron_cluster_map[neuron] = i

        for neuron in self.neurons:
            if neuron not in neuron_cluster_map:
                continue

            # Only split elongated cells
            if not hasattr(neuron.cell.sphere, "scale"):
                continue

            scale = neuron.cell.sphere.scale()
            if scale[2] < elongation_threshold:
                continue

            cluster_idx = neuron_cluster_map[neuron]
            cluster_center = cluster_centers[cluster_idx]

            # Apical-basal axis is center-to-cell
            ab_axis = normalize_vector(cluster_center - neuron.cell.position)
            split_offset = ab_axis * split_distance

            # New position along apical-basal axis
            new_position = neuron.cell.position + split_offset
            new_neuron = self.create_new_neuron(new_position)
            new_neuron.cell.sphere.scale(scale)  # Copy scale

            # Optional: apply a little jitter for visual realism
            jitter = np.random.uniform(-0.3, 0.3, size=3)
            new_neuron.cell.position += jitter

            new_neurons.append(new_neuron)

        self.neurons.extend(new_neurons)
        self.update_drawings()
        print(f"üß¨ Split {len(new_neurons)} new neurons along apical-basal axis.")
        
    def apply_lumenation(self, lumen_factor=0.1):
        """
        Gently pushes neurons outward from their respective cluster centers.
        """
        clusters = self.find_clusters(distance_threshold=6.0)

        for cluster in clusters:
            cluster_center = np.mean([n.cell.position for n in cluster], axis=0)

            for neuron in cluster:
                direction_outward = normalize_vector(neuron.cell.position - cluster_center)
                neuron.cell.position += direction_outward * lumen_factor
                if hasattr(neuron.cell, "sphere"):
                    neuron.cell.sphere.pos(neuron.cell.position)

        self.lumenation_complete = True
        print("üåü Lumenation complete.")

    def apply_elongation(self, elongation_factor=0.05):
        """
        Slightly grows cells with pointed ends aligned radially
        (toward/away from their assigned cluster center).
        """
        # Get all clusters
        clusters = self.find_clusters(distance_threshold=6.0)

        for cluster in clusters:
            cluster_center = np.mean([n.cell.position for n in cluster], axis=0)

            for neuron in cluster:
                if not hasattr(neuron, "original_vertices"):
                    neuron.original_vertices = np.copy(neuron.cell.sphere.points())

                cell_center = neuron.cell.position
                direction_to_center = normalize_vector(cell_center - cluster_center)
                new_vertices = []

                for vertex in neuron.original_vertices:
                    direction = normalize_vector(vertex - cell_center)
                    projection = np.dot(direction, direction_to_center)
                    displacement = direction * (elongation_factor * projection)
                    new_vertices.append(vertex + displacement)

                neuron.cell.sphere.points(np.array(new_vertices), transformed=True)

        self.elongation_complete = True
        print("‚úÖ Elongation complete! Moving to lumenation.")



#4:30 AM
    # def apply_elongation(self, elongation_factor=1.5, alignment_duration=10.0):
    #     """
    #     Gradually elongates each neuron along its apical-basal axis over `alignment_duration` seconds.

    #     Instead of using `.scale()`, we move the vertices of the sphere mesh along the identified
    #     apical-basal direction to ensure stability in Vedo.
    #     """
    #     current_time = self.timer.current_time

    #     if not hasattr(self, "elongation_start_time"):
    #         self.elongation_start_time = current_time  # Set the start time

    #     elapsed_time = current_time - self.elongation_start_time
    #     elongation_progress = min(elapsed_time / alignment_duration, 1.0)  # Normalize (0 ‚Üí 1)

    #     for neuron in self.neurons:
    #         if not hasattr(neuron, "elongated"):
    #             neuron.elongated = False  # Track elongation state

    #         # **Determine the apical-basal axis** (already randomized in polarization step)
    #         apical_dir = normalize_vector(neuron.cell.position)  # Assuming it's defined
    #         basal_dir = -apical_dir  # Opposite direction

    #         # **Store original positions for smooth elongation**
    #         if not hasattr(neuron, "original_vertices"):
    #             neuron.original_vertices = np.copy(neuron.cell.sphere.points())

    #         # **Apply elongation over time**
    #         new_vertices = []
    #         for vertex in neuron.original_vertices:
    #             # Compute how far to stretch the vertex along the apical-basal axis
    #             displacement = apical_dir * (elongation_progress * elongation_factor)

    #             # Stretch based on whether the vertex is on the apical or basal side
    #             if np.dot(vertex - neuron.cell.position, apical_dir) > 0:
    #                 new_vertex = vertex + displacement  # Move in apical direction
    #             else:
    #                 new_vertex = vertex - displacement  # Move in basal direction
                
    #             new_vertices.append(new_vertex)

    #         # Update the cell's mesh vertices smoothly
    #         neuron.cell.sphere.points(np.array(new_vertices), transformed=True)

    #         # ‚úÖ Mark as fully elongated when the transition completes
    #         if elongation_progress >= 1.0:
    #             neuron.elongated = True  # Lock elongation
    #             self.elongation_complete = True  # Mark simulation phase complete
    #             print(f"‚úÖ Elongation **complete**! Moving to lumenation.")

    def induce_rosette_folding(self):
        """Apically constricts cells, initiating inward curvature."""
        lumen_center = np.mean([n.cell.position for n in self.neurons], axis=0)
        for neuron in self.neurons:
            neuron.cell.position = 0.8 * neuron.cell.position + 0.2 * lumen_center  # Pull toward center
            neuron.cell.sphere.scale([0.8, 0.8, 1.0])  # Y-axis elongation
            neuron.cell.sphere.color("purple")  # Mark rosette forming


    def find_clusters(self, distance_threshold: float) -> List[List[Neuron]]:
        """
        Groups neurons into clusters based on a distance threshold.

        Parameters
        ----------
        distance_threshold : float
            The maximum distance between neurons to be considered part of the same cluster.

        Returns
        -------
        List[List[Neuron]]
            A list of clusters, where each cluster is a list of neurons.
        """
        clusters = []
        visited = set()

        for neuron in self.neurons:
            if neuron not in visited:
                cluster = self._dfs_cluster(neuron, distance_threshold, visited)
                clusters.append(cluster)
        return clusters

    def _dfs_cluster(self, neuron: Neuron, distance_threshold: float, visited: set) -> List[Neuron]:
        """
        Performs a depth-first search to find all neurons in the same cluster.

        Parameters
        ----------
        neuron : Neuron
            The starting neuron for the search.
        distance_threshold : float
            The maximum distance between neurons to be considered part of the same cluster.
        visited : set
            A set to keep track of visited neurons.

        Returns
        -------
        List[Neuron]
            A list of neurons in the same cluster as the starting neuron.
        """
        stack = [neuron]
        cluster = []

        while stack:
            current = stack.pop()
            if current not in visited:
                visited.add(current)
                cluster.append(current)
                for neighbor in self._get_neighbors(current, distance_threshold):
                    if neighbor not in visited:
                        stack.append(neighbor)
        return cluster

    def _get_neighbors(self, neuron: Neuron, distance_threshold: float) -> List[Neuron]:
        """
        Finds all neighbors of a neuron within a given distance.

        Parameters
        ----------
        neuron : Neuron
            The neuron for which to find neighbors.
        distance_threshold : float
            The maximum distance to consider a neighbor.

        Returns
        -------
        List[Neuron]
            A list of neighboring neurons.
        """
        neighbors = []
        neuron_position = neuron.cell.position  # Access the correct position attribute

        for other_neuron in self.neurons:
            other_position = other_neuron.cell.position  # Access the position of the other neuron
            if other_neuron != neuron and np.linalg.norm(neuron_position - other_position) <= distance_threshold:
                neighbors.append(other_neuron)
        return neighbors

        # try:
        #     neuron_position = neuron.cell.position  # Correctly access the position attribute
        # except AttributeError:
        #     raise AttributeError("Neuron object does not have a 'cell.position' attribute. Check the Neuron class definition.")

        # for other_neuron in self.neurons:
        #     try:
        #         other_position = other_neuron.cell.position  # Access the position of other neurons
        #     except AttributeError:
        #         continue  # Skip if the neuron doesn't have a valid position

        #     if other_neuron != neuron and np.linalg.norm(neuron_position - other_position) <= distance_threshold:
        #         neighbors.append(other_neuron)

        # return neighbors
    def check_rosette_formation(self, min_time_before_check: float = 150.0) -> bool:
        """
        Checks if any clusters meet the threshold for rosette formation.

        Parameters
        ----------
        min_time_before_check : float
            The minimum time that must pass before checking for rosettes.

        Returns
        -------
        bool
            True if at least one cluster meets the threshold for rosette formation, False otherwise.
        """

        # Ensure enough time has passed before checking for rosettes
        if self.timer.current_time < min_time_before_check:
            print(f"Skipping rosette check at time {self.timer.current_time}. Not enough time has passed.")
            return False  # Do not check too early

        clusters = self.find_clusters(distance_threshold=5.0)  

        # Debugging: Log cluster formation
        print(f"Number of clusters detected: {len(clusters)} at time {self.timer.current_time}")

        for i, cluster in enumerate(clusters):
            # Increase the threshold for detecting real rosettes
            if len(cluster) >= 4:  
                print(f"Rosette formation detected in Cluster {i} (size: {len(cluster)})")
                return True  # A rosette is confirmed

        print("No rosettes detected this cycle.")
        return False  # No valid clusters met the threshold
    def replicate_neuron(self, parent_neuron):
        displacement = np.random.uniform(-1.0, 1.0, size=3)  # Slight offset
        new_position = parent_neuron.cell.position + displacement

        new_neuron = self.neuron_factory.create_neuron(coordinates=new_position)

        new_neuron.cell.sphere.color("green")  # Visualize new cells differently
        new_neuron.cell.sphere.scale([1.0, 1.0, 1.0])
        
        # Reset parent cycle clock
        parent_neuron.clocks.cycle_clock.reset()
        return new_neuron


    def update_sphere_colors_and_deform(self, time_step: float):
        """
        Handles visualization updates based on the current phase.
        NO PHYSICS OR FORCE APPLICATIONS SHOULD BE HERE.
        """

        print(f"üìå Time {self.timer.current_time}: Updating visualization...")

        # **Clustering Phase**: All cells are blue
        if not self.clustering_complete:
            for neuron in self.neurons:
                neuron.cell.sphere.color("blue")
                # **Elongation Phase**: Make neurons light blue
        elif self.polarization_complete and not self.elongation_complete:
            for neuron in self.neurons:
                neuron.cell.sphere.color("blue")

        # **Lumenation Phase**: Make neurons light green
        elif self.elongation_complete and not self.lumenation_complete:
            for neuron in self.neurons:
                neuron.cell.sphere.color("lightgreen")

        # **Render Once at the End**
        self.animator.plotter.render()


    def update_indicator(self):
        """
        Updates the indicator color based on rosette formation status.
        """
        # Re-check clusters to determine rosette formation status
        clusters = self.find_clusters(distance_threshold = 9.0)  # Ensure the threshold matches elsewhere
        self.rosette_formed = any(len(cluster) >= 3 for cluster in clusters)

        if self.rosette_formed:
            self.indicator_color = "green"
        else:
            self.indicator_color = "blue"
        print(f"Indicator updated to: {self.indicator_color}")

        # Ensure the animator reflects this change visually
        self.animator.update_indicator(color=self.indicator_color)

    def jiggle_neurons(self, jiggle_magnitude: float = 0.10) -> None:
        """
        Jiggling with dynamic control based on time or density.
        """
        current_density = len(self.neurons) / self.grid.total_volume
        adjusted_magnitude = max(0.10, jiggle_magnitude * (1 - current_density))  # Reduce jiggle as density increases

        for neuron in self.neurons:
            jiggle_vector = np.random.uniform(-jiggle_magnitude, jiggle_magnitude, size=3)
            neuron.cell.position += jiggle_vector
            neuron.cell.sphere.pos(neuron.cell.position)
        self.animator.plotter.render()
    def check_and_flag_neurons_for_death(self):
        """Flag neurons for removal based on lifetime/age conditions."""
        for neuron in self.neurons:
            if not hasattr(neuron, "lifetime"):
                neuron.lifetime = np.random.uniform(100, 200)  # You can tweak range
            if not hasattr(neuron, "age"):
                neuron.age = 0

            neuron.age += 1

            if neuron.age > neuron.lifetime:
                neuron.ready_to_die = True
                print(f"‚ùå Neuron {neuron} marked for death (age: {neuron.age}, lifetime: {neuron.lifetime})")
                num_flagged = sum(getattr(n, "ready_to_die", False) for n in self.neurons)
                print(f"‚ö†Ô∏è Neurons flagged for death this step: {num_flagged}")

    def perform_neuron_death_cleanup(self):
        """Actually remove neurons flagged for death from the container and plot."""
        neurons_to_keep = []
        for neuron in self.neurons:
            if getattr(neuron, "ready_to_die", False):
                # Visual cleanup
                self.animator.plotter -= neuron.cell.sphere
                for neurite in neuron.neurites:
                    self.animator.plotter -= neurite.cylinder[0]
                    self.animator.plotter -= neurite.cylinder[1]
                print(f"üóëÔ∏è Neuron {neuron} deleted.")
            else:
                neurons_to_keep.append(neuron)
        self.neurons = neurons_to_keep

    def check_and_trigger_neuron_division(self):
        """Check neurons for division and divide if conditions are met."""
        new_neurons = []
        for neuron in self.neurons:
            if not hasattr(neuron.clocks.cycle_clock, "time_to_division"):
                neuron.clocks.cycle_clock.time_to_division = 100  # initial setting

            if not neuron.ready_for_division:
                neuron.clocks.cycle_clock.time_to_division -= 10
                continue

            # You can add density logic here if needed

            # Spread new neurons outward
            spread_factor = np.random.uniform(5.0, 10.0)
            direction = get_random_unit_vector(two_dimensions=self.simulation_2d)
            new_pos = neuron.cell.position + (direction * neuron.cell_radius * spread_factor)

            # Avoid collisions
            while any(np.linalg.norm(new_pos - other.cell.position) < 2.5 * neuron.cell_radius for other in self.neurons):
                direction = get_random_unit_vector(two_dimensions=self.simulation_2d)
                new_pos = neuron.cell.position + (direction * neuron.cell_radius * spread_factor)

            new_neuron = self.create_new_neuron(new_pos)
            new_neuron.cell.sphere.scale([1.0, 1.0, 1.0])

            # Slight jitter
            jitter = np.random.uniform(-0.5, 0.5, size=3)
            new_neuron.cell.position += jitter

            neuron.clocks.cycle_clock.remove_flag()
            new_neurons.append(new_neuron)
            print(f"üß¨ Neuron {neuron} divided. New neuron created at {new_pos}.")

        self.neurons.extend(new_neurons)
        self.update_drawings()

    def update(self): 
        """
        Updates the simulation container by advancing cycles, handling differentiation,
        killing neurons, and updating drawings.
        """
        self.advance_cycles(self.timer.step)
        self.kill()
        self.differentiate()
        self.divide()
        self.solve_mechanics(self.timer.step)
        self.update_drawings()


    def advance_cycles(self, time_step: float) -> None:
        """Advances the simulation and applies trend-based modifications based on rosette formation parameters."""
        self.divide()
        self.timer.current_time += time_step
        print(f"‚è© Updated time: {self.timer.current_time}")
    # In `advance_cycles` or simulation loop:
        # for neuron in self.neurons:
        #     if not hasattr(neuron, "lifetime"):
        #         neuron.lifetime = np.random.uniform(100, 200)
        #     if not hasattr(neuron, "age"):
        #         neuron.age = 0
        #     neuron.age += 1
        #     if neuron.age > neuron.lifetime:
        #         neuron.ready_to_die = True
        # for neuron in self.neurons:
        #     self.kill()
        #     self.divide()
        # üîÅ Lifecycle management
        # self.check_and_flag_neurons_for_death()
        # self.perform_neuron_death_cleanup()
        # self.check_and_trigger_neuron_division()

              # Compute Phase Parameters
        C = compute_clustering_coefficient(self.neurons)
        NNV = compute_nearest_neighbor_variance(self.neurons)
        H = compute_orientation_entropy(self.neurons)
        AR = compute_aspect_ratio(self.neurons)
        RSI = compute_radial_symmetry(self.neurons)

        # Log parameters
        print(f"üìä C: {C:.4f}, NNV: {NNV:.4f}, H: {H:.4f}, AR: {AR:.4f}, RSI: {RSI:.4f}")
        print(f"üî¢ Total neurons: {len(self.neurons)}")
        # 1Ô∏è‚É£ **Clustering Phase**
        if not self.clustering_complete:
            # while True:
                # üß† Continuous directional jiggle for all neurons
            for neuron in self.neurons:
                # Random small directional movement (jiggle + slight bias outward from center)
                center = np.array([0.0, 0.0, 0.0])
                direction = neuron.cell.position - center
                if np.linalg.norm(direction) == 0:
                    direction = np.random.uniform(-1, 1, size=3)
                direction = direction / np.linalg.norm(direction)

                jiggle = np.random.uniform(-0.02, 0.02, size=3)
                directional_bias = 0.01 * direction  # Adjust magnitude of outward motion

                neuron.cell.position += jiggle + directional_bias

            print(f"üìå Clustering in progress...")
            # self.apply_clustering_force()
            self.apply_density_aware_clustering_force
            # Inside your simulation loop

        time_interval = 0.25  # seconds
        previous_time = self.timer.current_time - time_step
        current_time = self.timer.current_time

        # Trigger only when crossing an exact multiple of `time_interval`
        # if not hasattr(self, "pre_polarization_scaled"):
        if int(previous_time // time_interval) < int(current_time // time_interval):
            print(f"‚è±Ô∏è Triggered at time {current_time:.2f}")
            self.replicate_clusters_balanced(target_cluster_size=random.randint(1, 6))


            # Check if clustering is complete
            avg_distance = np.mean([
                np.linalg.norm(n.cell.position - np.mean([m.cell.position for m in self.neurons], axis=0))
                for n in self.neurons
            ])
            clusters = self.find_clusters(distance_threshold=4.5)
            avg_cluster_coef = compute_average_cluster_coefficient(clusters)

            if avg_cluster_coef > 0.16 and current_time == 4.5 and AR == 1:
                self.clustering_complete = True
                # before_count = len(self.neurons)
                # self.remove_outlier_neurons(removal_threshold=3.5, min_cluster_size=20)
                # after_count = len(self.neurons)
                # removed = before_count - after_count

                # print(f"üß† Neurons before: {before_count}, after: {after_count}, removed: {removed}")
                print("‚úÖ Clustering complete! Moving to constriction.")

                     # **New Step: Compact clusters before spreading**
                self.compact_clusters_spherically(attraction_strength=-0.1, iterations=20)

                # self.replicate_clusters_balanced(target_cluster_size=30)

                # 2Ô∏è‚É£ Gradual spreading after clustering, added after the spread force added to remove_outlier_neurons
        if self.clustering_complete and not hasattr(self, "clusters_spread"):
            self.apply_cluster_spread(spread_strength=0.49)  # <‚Äî adjust as needed
            self.clusters_spread = True  # ‚Üê use a **separate flag**
            self.replicate_clusters_balanced(target_cluster_size=30)
               
                # üìä Log current cluster status
        # clusters = self.find_clusters(distance_threshold=4.5)
        # print(f"üî¢ Total neurons: {len(self.neurons)}")
        # for i, cluster in enumerate(clusters):
        #     print(f"üß† Cluster {i+1} size: {len(cluster)}")

        # üß¨ Scaling Phase - before polarization starts
        if self.clustering_complete and hasattr(self, "clusters_spread") and not hasattr(self, "pre_polarization_scaled"):
            print("üì¶ Scaling neurons slightly before polarization...")

            for neuron in self.neurons:
                if hasattr(neuron.cell, "sphere"):
                    neuron.cell.sphere.scale([0.8, 0.8, 2.0])  # üîç Adjust scale as needed

            self.pre_polarization_scaled = True  # ‚úÖ Only scale once

        elif self.clustering_complete and not self.polarization_complete:
            print(f"üìå Polarization and Elongation in progress...")    

            # üîÑ **Apply polarity with spreading & gradual alignment**
            self.apply_polarity_establishment(spread_factor=0.035, alignment_duration=4.0)
            # self.split_elongated_cells()

            # ‚úÖ **Check if polarization is complete**
        if self.polarization_complete:

            print(f"‚úÖ Polarization and Elongation **complete**! Moving to lumen formation.")


        if self.polarization_complete and not self.elongation_complete:
            print(f"üìå Lumenation in progress...")
            # self.project_clusters_onto_plane_gradually(projection_duration=2.0)
            # self.spread_apart_clusters(spread_distance=30.0, spread_duration=2.0, spread_speed=0.05)
            # elongation_factor = 0.025  # Adjust elongation intensity

            # self.apply_elongation(elongation_factor=elongation_factor)
            


        elif self.elongation_complete and not self.lumenation_complete:
            print(f"üí° Lumenation in progress...")
            # self.apply_lumenation(lumen_factor=0.1)
            # # Get the current cluster center
            # cluster_center = np.mean([n.cell.position for n in self.neurons], axis=0)

            # # Define duration for smooth lumenation
            # lumen_duration = 30.0
            # current_time = self.timer.current_time

            # if not hasattr(self, "lumenation_start_time"):
            #     self.lumenation_start_time = current_time  # Set start time

            # elapsed_time = current_time - self.lumenation_start_time
            # lumen_progress = min(elapsed_time / lumen_duration, 1.0)  # Normalize (0 ‚Üí 1)

            # for neuron in self.neurons:
            #     direction_from_center = normalize_vector(neuron.cell.position - cluster_center)
                
            #     # **Move outward gradually over time**
            #     neuron.cell.position += direction_from_center * 0.241 * lumen_progress  

            # # ‚úÖ Mark lumenation complete
            # if lumen_progress >= 1.0:
            #     self.lumenation_complete = True
            #     print(f"‚úÖ Lumenation **complete**! Final structure achieved.")













        # """
        # Checks if conditions for rosette formation are met.
        # Returns True if rosette formation is detected, otherwise False.
        # """
        # # Define criteria for rosette formation. For example:
        # # - Check if a certain number of neurons are in close proximity (clustered)
        # # - Check if all neurons have extended a minimum number of neurites
        # # Example: assuming rosette formation means each neuron has at least 2 neurites and forms a cluster
        # cluster_threshold = 3  # Example threshold for cluster size
        # clustered_neurons = [
        #     neuron for neuron in self.neurons
        #     if len(neuron.neurites) >= 2  # Example neurite condition
        #     and self.is_neuron_clustered(neuron, cluster_threshold)  # Check clustering
        # ]
        
        # # If enough neurons meet the criteria, we consider the rosette formed
        # return len(clustered_neurons) >= cluster_threshold

    # def is_neuron_clustered(self, neuron: Neuron, distance_threshold: float) -> bool:
    #     """
    #     Checks if a neuron is within a certain distance of enough neighboring neurons.

    #     Parameters
    #     ----------
    #     neuron : Neuron
    #         The neuron to check for clustering.
    #     distance_threshold : float
    #         The distance threshold for considering a neuron as part of a cluster.

    #     Returns
    #     -------
    #     bool
    #         True if the neuron is clustered with others, False otherwise.
    #     """
    #     nearby_neurons = [
    #         other_neuron for other_neuron in self.neurons
    #         if other_neuron is not neuron
    #         and np.linalg.norm(neuron.cell.position - other_neuron.cell.position) < distance_threshold
    #     ]
    #     return len(nearby_neurons) >= 3  # Example condition: clustered if at least 3 nearby neurons

    # def update_indicator(self):
    #     """Updates the color of the indicator based on rosette formation status."""
    #     if self.rosette_formed:
    #         self.indicator_color = "green"  # Rosette formation detected
    #     else:
    #         self.indicator_color = "blue"  # No rosette formation detected
    #     self.animator.update_indicator(color=self.indicator_color)  # Update indicator in animator

    # def advance_cycles(self, time_step: float) -> None:
    #     """
    #     Updates the biological clocks of every object in the simulation and checks for rosette formation.

    #     Parameters
    #     ----------
    #     time_step
    #         The time between simulation time points.
    #     """
    #     for neuron in self.neurons:
    #         neuron.clocks.advance_clocks(time_step)

    #     # Check rosette formation
    #     if not self.rosette_formed and self.check_rosette_formation():
    #         self.rosette_formed = True  # Update the rosette formation status

    #     # Update the indicator color based on rosette status
    #     self.update_indicator()

    def set_density_check(self, density_check: CellDensityCheck) -> None:
        """
        Sets the contact inhibition function to be used before proliferation.

        Parameters
        ----------
        density_check
            The contact inhibition function to be used.
        """
        self.density_check = density_check

    def register_neuron(self, neuron: Neuron, color="blue") -> None:
        """
        Registers a neuron and its representation into the container.

        Parameters
        ----------
        neuron
            The new neuron to be registered.
        color
            The color of the sphere that will represent the new neuron
            in the renderings of the simulation.
        """
        neuron.cell.set_sphere_representation(self.animator, color=color)
        self.grid.register_cell(neuron.cell)
        for neurite in neuron.neurites:
            neurite.create_neurite_representation(self.animator)
            self.grid.register_neurite(neurite)

        self.neurons.append(neuron)
    


    def update_drawings(self) -> None:
        """Updates the representations of the neurons"""
        for neuron in self.neurons:
            neuron.cell.update_representation()
            for neurite in neuron.neurites:
                neurite.update_representation()

        self.animator.plotter.show()

    # def advance_cycles(self, time_step: float) -> None:
    #     """
    #     Updates the biological clocks of every object in the simulation.

    #     Parameters
    #     ----------
    #     time_step
    #         The time between simulation time points.
    #     """
    #     for neuron in self.neurons:
    #         neuron.clocks.advance_clocks(time_step)

    # def create_new_neuron(
    #     self,
    #     coordinates: Union[np.ndarray, List[float]],
    #     outgrowth_axis: Optional[Union[List[float], np.ndarray]] = None,
    #     color="darkblue",
    # ) -> Neuron:
    def create_new_neuron(self, coordinates: List[float]) -> Neuron:
        outgrowth_axis = np.subtract([0,0,0], coordinates)
        """Creates a new neuron at the given coordinates."""
        neuron = self.neuron_factory.create_neuron(coordinates, outgrowth_axis)
        neuron.cell.set_sphere_representation(self.animator, color="blue")  # Initial color
        neuron.cell.sphere.scale([0.5, 0.5, 0.5])  # Ensure spherical shape
        self.neurons.append(neuron)
        return neuron

        """
        Creates a new neuron and registers it to the container's grid.

        The new neuron is created as an undifferentiated cell body centred at
        the passed coordinates. An outgrowth axis vector can be passed to model
        neurite outgrowth along this direction.

        Parameters
        ----------
        coordinates
            The center position of the neuron's cell body.
        outgrowth_axis
            The direction of growth of the neuron's neurites.
        color
            The color of the new neurite in the simulation renders.
        """
        if isinstance(coordinates, list):
            coordinates = np.array(coordinates)

        if not isinstance(outgrowth_axis, np.ndarray):
            if isinstance(outgrowth_axis, list):
                outgrowth_axis = np.array(outgrowth_axis)
            else:
                outgrowth_axis = get_random_unit_vector(
                    two_dimensions=self.simulation_2d
                )

        new_neuron = self.neuron_factory.create_neuron(coordinates, outgrowth_axis)
        self.register_neuron(new_neuron, color=color)

        return new_neuron
    def replicate_clusters_balanced(self, target_cluster_size=30):
        """
        Replicates neurons in smaller clusters to balance cluster sizes.
        - `target_cluster_size`: Desired number of neurons in each cluster.
        """
        if len(self.neurons) < 2:
            return

        # Find clusters
        clusters = self.find_clusters(distance_threshold=4.5)
        print(f"üîç Found {len(clusters)} clusters for replication check.")

        # Sort clusters by size (ascending to prioritize smaller ones)
        clusters_sorted = sorted(clusters, key=len)

        total_new_neurons = 0

        for cluster in clusters_sorted:
            current_size = len(cluster)
            if current_size >= target_cluster_size:
                continue  # Skip well-populated clusters

            # Compute how many neurons to replicate
            neurons_needed = target_cluster_size - current_size
            print(f"üìà Replicating {neurons_needed} neurons for a cluster of size {current_size}")

            for _ in range(neurons_needed):
                # Randomly pick a neuron from the cluster to replicate
                source_neuron = np.random.choice(cluster)
                jitter = np.random.normal(scale=2.0, size=3)  # Add small spatial noise
                new_position = source_neuron.cell.position + jitter
                self.create_new_neuron(new_position)
                total_new_neurons += 1

        print(f"‚úÖ Replicated {total_new_neurons} new neurons across underpopulated clusters.")

    def differentiate(self) -> None:
        """Checks for neurons that are flagged for differentiation and deals with differentiation"""
        new_neurons = []
        for neuron in self.neurons:
            if not neuron.ready_for_differentiation:
                neuron.clocks.advance() #fast forwards cell cycle
                continue
            neuron.clocks.differentiation_clock.differentiation_signal = False
            # if (
            #     not neuron.ready_for_differentiation
            #     or len(neuron.neurites) >= neuron.max_number_of_neurites
            # ):
            #     continue
            # # Decide whether to create a new neurite or extend an existing one
            # if neuron.neurites:
            #     neurite = neuron.create_secondary_neurite(self.object_factory)
            #     neurite = neuron.neurites[-1]

            #     nearby_neurites = [
            #         nearby_object
            #         for nearby_object in self.grid.get_close_objects(
            #             neurite.distal_point
            #         )
            #         if isinstance(nearby_object, Neurite)
            #     ]

            #     nearby_neurites = [
            #         neurite
            #         for neurite in nearby_neurites
            #         if neurite not in neuron.neurites
            #     ]

            #     keep_going = True
            #     clear = [False for _ in nearby_neurites]

            #     while not all(clear) and keep_going:
            #         for i, neighbor in enumerate(nearby_neurites):

            #             neurite_axis = neurite.spring_axis

            #             if intersect(
            #                 neurite.proximal_point,
            #                 neurite.distal_point,
            #                 neighbor.proximal_point,
            #                 neighbor.distal_point,
            #             ):
            #                 good_point = get_cylinder_intersection(
            #                     neurite.proximal_point,
            #                     neurite.distal_point,
            #                     neighbor.proximal_point,
            #                     neighbor.distal_point,
            #                 )[0]

            #                 length = np.linalg.norm(
            #                     np.subtract(good_point, neurite.proximal_point)
            #                 )

            #                 if length < 5.0:
            #                     keep_going = False
            #                     neuron.neurites.pop(-1)
            #                     break

            #                 fraction = length / neurite.current_length

            #                 neurite.distal_point = (
            #                     neurite.proximal_point + fraction * neurite_axis
            #                 )
            #                 neurite.mechanics.default_length = np.linalg.norm(
            #                     neurite.spring_axis
            #                 )
            #                 clear[i] = True

            #             else:
            #                 clear[i] = True

            #     if all(clear):
            #         neurite.create_neurite_representation(self.animator)
            #         self.grid.register_neurite(neurite)

            # else:
            #     neuron.create_first_neurite(self.object_factory)
            #     neurite = neuron.neurites[0]

            #     nearby_neurites = [
            #         nearby_object
            #         for nearby_object in self.grid.get_close_objects(
            #             neurite.distal_point
            #         )
            #         if isinstance(nearby_object, Neurite)
            #     ]

            #     keep_going = True
            #     clear = [False for _ in nearby_neurites]

            #     while not all(clear) and keep_going:
            #         for i, neighbor in enumerate(nearby_neurites):

            #             neurite_axis = neurite.spring_axis

            #             if intersect(
            #                 neurite.proximal_point,
            #                 neurite.distal_point,
            #                 neighbor.proximal_point,
            #                 neighbor.distal_point,
            #             ):
            #                 good_point = get_cylinder_intersection(
            #                     neurite.proximal_point,
            #                     neurite.distal_point,
            #                     neighbor.proximal_point,
            #                     neighbor.distal_point,
            #                 )[0]

            #                 length = np.linalg.norm(
            #                     np.subtract(good_point, neurite.proximal_point)
            #                 )

            #                 if length < 5.0:
            #                     keep_going = False
            #                     neuron.neurites.pop(-1)
            #                     break

            #                 fraction = length / neurite.current_length

            #                 neurite.distal_point = (
            #                     neurite.proximal_point + fraction * neurite_axis
            #                 )
            #                 neurite.mechanics.default_length = np.linalg.norm(
            #                     neurite.spring_axis
            #                 )
            #                 clear[i] = True

            #             else:
            #                 clear[i] = True

            #     if all(clear):
            #         neurite.create_neurite_representation(self.animator)
            #         self.grid.register_neurite(neurite)

            # neuron.clocks.differentiation_clock.differentiation_signal = False

    def kill(self) -> None:
        """
        Removes neurons flagged for death and their visual + grid representations.
        """
        neurons_to_kill = [n for n in self.neurons if getattr(n, "ready_to_die", False)]

        for neuron in neurons_to_kill:
            if hasattr(neuron.cell, "sphere"):
                self.animator.plotter -= neuron.cell.sphere

            for neurite in neuron.neurites:
                for cylinder in neurite.cylinder:
                    self.animator.plotter -= cylinder

            self.neurons.remove(neuron)

        if neurons_to_kill:
            print(f"üíÄ Removed {len(neurons_to_kill)} neurons marked for death.")

   
   
   
   
    # def kill(self) -> None:
    #     """Checks for neurons that are flagged for death and removes them from the container"""
    #     initial_count = len(self.neurons)
    #     killed_count = 0
    #     for neuron in self.neurons[:]:
    #         if not neuron.ready_to_die:
    #             continue
    #         # Remove neuron and its representation
    #         self.animator.plotter -= neuron.cell.sphere
    #         for neurite in neuron.neurites:
    #             self.animator.plotter -= neurite.cylinder[0]
    #             self.animator.plotter -= neurite.cylinder[1]
    #         self.neurons.remove(neuron)
    #         killed_count += 1
    #     if killed_count > 0:
    #         print(f"üíÄ Killed {killed_count} neurons. Remaining: {len(self.neurons)}")

    def divide(self) -> None:
        """
        Handles neuron division logic, creating new neurons while maintaining constraints
        on density and cell cycle state. Now optimized for frequent division.
        """
        new_neurons = []
        division_count = 0

        for neuron in self.neurons:
            # Initialize or decrement time_to_division
            if not hasattr(neuron.clocks.cycle_clock, "time_to_division"):
                neuron.clocks.cycle_clock.time_to_division = 50  # LOWERED from 100
            else:
                neuron.clocks.cycle_clock.time_to_division -= 5  # FASTER progression

            if neuron.clocks.cycle_clock.time_to_division > 0:
                continue  # Still not ready

            if not neuron.ready_for_division:
                continue

            if self.density_check:
                if self.density_check.check_max_density(neuron.cell, self.grid):
                    print("‚ö†Ô∏è Skipping division due to density constraint")
                    neuron.clocks.cycle_clock.remove_flag()
                    neuron.clocks.cycle_clock.trigger_block()
                    continue

            # Calculate position for new neuron
            spread_factor = np.random.uniform(4.0, 8.0)
            direction_vector = get_random_unit_vector(two_dimensions=self.simulation_2d)
            new_position = neuron.cell.position + (direction_vector * neuron.cell_radius * spread_factor)

            # Ensure no overlap with neighbors
            while any(np.linalg.norm(new_position - other.cell.position) < 2.5 * neuron.cell_radius for other in self.neurons):
                direction_vector = get_random_unit_vector(self.simulation_2d)
                new_position = neuron.cell.position + (direction_vector * neuron.cell_radius * spread_factor)

            # Create and configure new neuron
            new_neuron = self.create_new_neuron(new_position)
            new_neuron.cell.sphere.scale([1.0, 1.0, 1.0])
            new_neuron.cell.sphere.color("limegreen")
            new_neuron.division_born_time = self.timer.current_time

            # ‚úÖ Add new division clock to child
            new_neuron.clocks.cycle_clock.time_to_division = 50

            jitter = np.random.uniform(-0.5, 0.5, size=3)
            new_neuron.cell.position += jitter

            new_neurons.append(new_neuron)
            neuron.clocks.cycle_clock.remove_flag()
            division_count += 1

        if new_neurons:
            print(f"üß¨ {division_count} neurons divided. Total: {len(self.neurons) + len(new_neurons)}")
            self.neurons.extend(new_neurons)
            self.update_drawings()


    # def divide(self) -> None:
    #     """
    #     Handles neuron division logic, creating new neurons while maintaining constraints
    #     on density and cell cycle state. Adds visual feedback for division.
    #     """
    #     new_neurons = []
    #     division_count = 0

    #     for neuron in self.neurons:
    #         if not neuron.ready_for_division:
    #             if not hasattr(neuron.clocks.cycle_clock, "time_to_division"):
    #                 neuron.clocks.cycle_clock.time_to_division = 100
    #             neuron.clocks.cycle_clock.time_to_division -= 10
    #             continue

    #         if self.density_check:
    #             if self.density_check.check_max_density(neuron.cell, self.grid):
    #                 neuron.clocks.cycle_clock.remove_flag()
    #                 neuron.clocks.cycle_clock.trigger_block()
    #                 continue

    #         spread_factor = np.random.uniform(5.0, 10.0)
    #         direction_vector = get_random_unit_vector(two_dimensions=self.simulation_2d)
    #         new_position = neuron.cell.position + (direction_vector * neuron.cell_radius * spread_factor)

    #         while any(np.linalg.norm(new_position - other.cell.position) < 2.5 * neuron.cell_radius for other in self.neurons):
    #             direction_vector = get_random_unit_vector(self.simulation_2d)
    #             new_position = neuron.cell.position + (direction_vector * neuron.cell_radius * spread_factor)

    #         new_neuron = self.create_new_neuron(new_position)
    #         new_neuron.cell.sphere.scale([1.0, 1.0, 1.0])

    #         jitter = np.random.uniform(-0.5, 0.5, size=3)
    #         new_neuron.cell.position += jitter

    #         # üåü Visual Feedback: flash green when created
    #         new_neuron.cell.sphere.color("limegreen").alpha(1.0)

    #         # Optional: store creation time to fade color later
    #         new_neuron.division_born_time = self.timer.current_time

    #         new_neurons.append(new_neuron)
    #         division_count += 1
    #         neuron.clocks.cycle_clock.remove_flag()

    #     self.neurons.extend(new_neurons)
    #     self.update_drawings()

    #     if division_count > 0:
    #         print(f"üß¨ {division_count} neurons divided. Total neurons: {len(self.neurons)}")

    # def divide(self) -> None:
    #     """
    #     Handles neuron division logic, creating new neurons while maintaining constraints
    #     on density and cell cycle state.
    #     """
    #     new_neurons = []
    #     for neuron in self.neurons:
    #         if not neuron.ready_for_division:
    #             # Decrement or initialize division timer safely
    #             if not hasattr(neuron.clocks.cycle_clock, "time_to_division"):
    #                 neuron.clocks.cycle_clock.time_to_division = 100  # Default threshold

    #             neuron.clocks.cycle_clock.time_to_division -= 10
    #             continue


    #         if self.density_check:
    #             # Check if the maximum density is reached
    #             if self.density_check.check_max_density(neuron.cell, self.grid):
    #                 # Prevent division and block further cycling
    #                 neuron.clocks.cycle_clock.remove_flag()
    #                 neuron.clocks.cycle_clock.trigger_block()
    #                 continue
    #         # Spread new neurons outward with a random direction and increased spacing
    #         spread_factor = np.random.uniform(5.0, 10.0)  # Increase for more spreading
    #         direction_vector = get_random_unit_vector(two_dimensions=self.simulation_2d)

    #         new_position = neuron.cell.position + (direction_vector * neuron.cell_radius * spread_factor)

    #         # Ensure new cell is not too close to existing ones
    #         while any(np.linalg.norm(new_position - other.cell.position) < 2.5 * neuron.cell_radius for other in self.neurons):
    #             new_position = neuron.cell.position + (get_random_unit_vector(self.simulation_2d) * neuron.cell_radius * spread_factor)

    #         # Create new neuron at spread-out position
    #         new_neuron = self.create_new_neuron(new_position)
    #         new_neuron.cell.sphere.scale([1.0, 1.0, 1.0])  # Keep new cells spherical

    #         # Apply slight random jitter to avoid rigid structures
    #         jitter = np.random.uniform(-0.5, 0.5, size=3)
    #         new_neuron.cell.position += jitter

    #         new_neurons.append(new_neuron)  # Add to the list of new neurons

    #         # Remove flag for next division cycle
    #         neuron.clocks.cycle_clock.remove_flag()

    #     # Extend the neuron list only after loop completes
    #     self.neurons.extend(new_neurons)
    #     self.update_drawings()  # Ensure visualization updates


            #     else:
            #         # Create a new neuron nearby
            #         position = (
            #             get_random_unit_vector(two_dimensions=self.simulation_2d)
            #             * neuron.cell_radius
            #             * np.random.uniform(2.0,3.5)  # Reduced spacing for tighter clusters
            #         )
            #         position += neuron.cell.position
            #         new_neuron = self.create_new_neuron(position)
            #         new_neuron.cell.sphere.scale([1.0, 1.0, 1.0])  # Ensure spherical shape

            #         # Apply a small random jiggle after division
            #         jiggle_vector = np.random.uniform(-0.1, 0.1, size=3)
            #         new_neuron.cell.position += jiggle_vector   

            #         # Update the original neuron's cycle state
            #         neuron.clocks.cycle_clock.remove_flag()
            #         self.update_drawings()
            # else:
            #     # Create a new neuron nearby without density check
            #     position = (
            #         get_random_unit_vector(two_dimensions=self.simulation_2d)
            #         * neuron.cell_radius
            #         * np.random.uniform(2.0,3.5)  # Reduced spacing for tighter clusters
            #     )
            #     position += neuron.cell.position
            #     new_neuron = self.create_new_neuron(position)
            #     new_neuron.cell.sphere.scale([1.0, 1.0, 1.0])  # Ensure spherical shape

            #     # Apply a small random jiggle after division
            #     jiggle_vector = np.random.uniform(-0.1, 0.1, size=3)
            #     new_neuron.cell.position += jiggle_vector 

            #     # Update the original neuron's cycle state
            #     neuron.clocks.cycle_clock.remove_flag()
            #     self.update_drawings()


    def get_displacement_from_force(
        self, force: np.ndarray, time_step: float
    ) -> np.ndarray:
        """
        Returns the displacemnt value that a force originates, based on the equation of motion.

        Parameters
        ----------
        force
            The force value to be converted to a displacement
        time_step
            The time passed between simulation time points.
        """
        velocity = force / self.drag_coefficient
        return velocity * time_step

    def move_cell(
        self, neuron: Neuron, new_coordinates: Union[np.ndarray, List[float]]
    ) -> None:
        """
        Moves the cell to a new position and updates the proximal point of the first neurite.

        Parameters
        ----------
        neuron
            The neuron object to be moved.
        new_coordinates
            The new coordinates to be assigned to the cell body's centre.
        """
        if isinstance(new_coordinates, list):
            new_coordinates = np.array(new_coordinates)

        self.grid.remove_cell(neuron.cell)
        neuron.cell.set_center_position(new_coordinates)
        self.grid.register_cell(neuron.cell)

        if neuron.neurites:
            neuron.place_neurite_on_cell_surface(neuron.neurites[0])

    def move_neurite(self, neurite: Neurite, new_coordinates: np.ndarray) -> None:
        """
        Deals with moving a neurite's distal point and updating it on the grid.

        Parameters
        ----------
        neurite
            The neurite object to be moved.
        new_coordinates
            The new coordinates to be assigned to the neurite's distal point.
        """
        self.grid.remove_neurite(neurite)
        neurite.move_distal_point(new_coordinates)
        self.grid.register_neurite(neurite)

    def compute_displacements(self, time_step) -> None:
        """
        Computes the displacement for each object based on the resulting force.

        Parameters
        ----------
        time_step
            The time passed between simulation time points.
        """
        for i, neuron in enumerate(self.neurons):
            reversed_order = range(len(neuron.neurites) - 1, -1, -1)

            for j, neurite in zip(reversed_order, reversed(neuron.neurites)):

                # Get force from spring
                force_spring = neurite.get_spring_force()
                neurite.force += force_spring
                # Transmit the opposite force to the mother neurite/cell
                # (Going through the neurites in reverse, once we arrive at 0 it is the last)
                if j > 0:
                    # Transmit to the mother neurite
                    neuron.neurites[j - 1].force_from_daughter -= force_spring
                else:
                    # Transmit to the cell
                    neuron.cell.force_from_daughter -= force_spring

                # Get force from daughter
                # Will contain force from spring and object interactions (the mother fraction)
                neurite.force += neurite.force_from_daughter

                # Get objects in the surrounding voxels
                nearby_objects = self.grid.get_close_objects(neurite.distal_point)
                nearby_cells = [
                    nearby_object
                    for nearby_object in nearby_objects
                    if isinstance(nearby_object, CellBody)
                ]
                nearby_neurites = [
                    nearby_object
                    for nearby_object in nearby_objects
                    if isinstance(nearby_object, Neurite)
                ]

                # Get forces from neighbor cells
                for neighbor in nearby_cells:
                    if neighbor is neuron.cell:
                        continue

                    # Cell force and fraction to be transmitted to the distal point
                    cell_force, fraction = neurite.get_cell_neighbor_force(
                        neighbor, self.sphere_cylinder_int
                    )

                    # Apply force to the distal point
                    neurite.force += cell_force * fraction
                    # Transmit force to the neighbor
                    neighbor.force_from_neighbors -= cell_force

                    # Transmit the force from cell to proximal part of the neurite
                    # (Going through the neurites in reverse, once we arrive at 0 it is the last)
                    if j > 0:
                        neuron.neurites[j - 1].force_from_daughter += cell_force * (
                            1 - fraction
                        )
                    else:
                        neuron.cell.force_from_daughter += cell_force * (1 - fraction)

                # Get forces from neighbor neurites
                for neighbor in nearby_neurites:
                    if neighbor in neuron.neurites:
                        continue

                    neurite_force, fraction = neurite.get_neurite_neighbor_force(
                        neighbor, self.cylinder_int
                    )
                    neurite.force += neurite_force * fraction

                    # Transmit the force from cell to proximal part of the neurite
                    # (Going through the neurites in reverse, once we arrive at 0 it is the last)
                    if j > 0:
                        neuron.neurites[j - 1].force_from_daughter += neurite_force * (
                            1 - fraction
                        )
                    else:
                        neuron.cell.force_from_daughter += neurite_force * (
                            1 - fraction
                        )

            # Get cell bodies close to the cell
            nearby_objects = self.grid.get_close_objects(neuron.cell.position)
            nearby_cells = [
                nearby_object
                for nearby_object in nearby_objects
                if isinstance(nearby_object, CellBody)
            ]

            for neighbor in nearby_cells:
                if neuron.cell is neighbor:
                    continue
                neuron.cell.force += neuron.cell.get_neighbor_force(
                    neighbor, self.sphere_int
                )

        for i, neuron in enumerate(self.neurons):
            for j, neurite in enumerate(neuron.neurites):
                neurite.force += neurite.force_from_daughter
                displacement = self.get_displacement_from_force(
                    neurite.force, time_step
                )
                self.neurons[i].neurites[j].displacement = displacement

            # Add the forces that were already calculated from other neurites
            neuron.cell.force += neuron.cell.force_from_daughter
            neuron.cell.force += neuron.cell.force_from_neighbors

            # Convert force value to displacement to assign new position
            displacement = self.get_displacement_from_force(
                neuron.cell.force, time_step
            )
            neuron.cell.displacement = displacement

    def update_cell_positions(self) -> None:
        """Updates the positions of all the simulation objects based on their velocity."""
        for neuron in self.neurons:
            neuron.cell.force = np.zeros(3)
            neuron.cell.force_from_neighbors = np.zeros(3)
            neuron.cell.force_from_daughter = np.zeros(3)

            for j, neurite in enumerate(neuron.neurites):
                neurite.force = np.zeros(3)
                neurite.force_from_daughter = np.zeros(3)
                self.move_neurite(neurite, neurite.distal_point + neurite.displacement)

                if j < len(neuron.neurites) - 1:
                    neuron.neurites[j + 1].move_proximal_point(
                        neuron.neurites[j].distal_point
                    )

            # Update the proximal position of the first neurite
            self.move_cell(neuron, neuron.cell.position + neuron.cell.displacement)

    def solve_mechanics(self, time_step) -> None:
        """
        Solves the mechanical interactions and updates the neurons' positions.

        Goes through each object and computes the resulting force acting on
        it, then gets the object's velocity based on the equation of motion.
        When all of the objects are checked, the positions are updated based
        on the calculated velocity.

        Parameters
        ----------
        time_step
            The time passed between simulation time points.
        """
        self.compute_displacements(time_step * 2)
        self.update_cell_positions()


class Simulation:
    """
    Class to create and run a simulation.

    Parameters
    ----------
    timer
        The structure to store the time data of the simulation.
    container
        The structure to store the spatial data of the simulation.
    """
    directory = r"C:\Users\16785\Desktop\neurorosette_code\tests\sim_images_newest"
    os.makedirs(directory, exist_ok=True)

    def __init__(self, timer: Timer, container: SimulationContainer):
        self.timer = timer
        self.container = container
        self.grid = container.grid
        self.neruon_factory = container.neuron_factory
        self.contact_factory = container.contact_factory

    def run(self, total_steps: int = 500) -> None:
        """Runs the entire simulation and ensures frames are saved correctly."""
        frame_count = 0
        
        # Ensure the correct save directory
        directory = r'C:\Users\16785\Desktop\neurorosette_code\tests\sim_images_newest'
        os.makedirs(directory, exist_ok=True)  # Force folder creation

        # üî¥ PRINT DEBUG INFO BEFORE STARTING
        print("\n‚úÖ DEBUG: Checking File Save Path")
        print(f"   Current Working Directory: {os.getcwd()}")
        print(f"   Target Save Directory: {directory}")

        # üî¥ TEST WRITING TO DIRECTORY
        test_file_path = os.path.join(directory, "debug_test.txt")
        try:
            with open(test_file_path, 'w') as f:
                f.write("Test Write Success!")
            print(f"‚úÖ SUCCESS: Test file written to {test_file_path}")
            os.remove(test_file_path)  # Cleanup
        except Exception as e:
            print(f"‚ùå ERROR: Cannot write to directory. Check folder permissions! {str(e)}")
            return  # Stop execution if folder is not writable

        print("\nüöÄ Starting simulation loop...")
        
        for step in range(total_steps):
            self.container.advance_cycles(self.timer.step)
            frame_count += 1

            if frame_count % 5 == 0:  # Save every 5 frames
                frame_path = os.path.abspath(os.path.join(directory, f'frame_{frame_count:05d}.png'))

                # üî¥ PRINT DEBUG INFO BEFORE SAVING
                print(f"\nüì∏ Attempting to save frame {frame_count} to: {frame_path}")

                try:
                    self.container.animator.plotter.render()  # Force render before saving
                    self.container.animator.save_screenshot(frame_path)

                    # üî¥ VERIFY IF FILE EXISTS AFTER SAVING
                    if os.path.exists(frame_path):
                        print(f"‚úÖ SUCCESS: Frame {frame_count} saved at {frame_path}")
                    else:
                        print(f"‚ùå ERROR: Frame {frame_count} was NOT saved. File missing!")

                except Exception as e:
                    print(f"‚ùå ERROR: Failed to save frame {frame_count}: {str(e)}")

        print("\nüéâ Simulation complete! Checking final saved files...")
        try:
            saved_files = os.listdir(directory)
            print(f"üìÇ Final contents of {directory}: {saved_files}")
        except Exception as e:
            print(f"‚ùå ERROR: Could not list directory contents: {str(e)}")


  


    def save_meshes(self, file_name: str) -> None:
        """
        Saves the neurons as PLY objects. Cell bodies are saved as spheres.
        Neurites are saved as cylinders.
        """
        # Save the cell bodies as one mesh (spheres)
        meshes = merge([neuron.cell.sphere for neuron in self.container.neurons])
        
        # Save the neurites as one mesh (cylinders)
        cylinders = []

        for neuron in self.container.neurons:
            for neurite in neuron.neurites:
                # Create a cylinder from the neurite's geometry
                cylinder = Cylinder(pos=neurite.proximal_point+0.5*neurite.spring_axis, 
                                    height=neurite.current_length, 
                                    axis=neurite.spring_axis/neurite.current_length,
                                    r=neurite.mechanics.radius)
                cylinders.append(cylinder)

        cylinder_meshes = merge(cylinders)

        # Save the result
        write(meshes, f"{file_name}_cells.ply")
        if cylinder_meshes:
            write(cylinder_meshes, f"{file_name}_neurites.ply")

    @classmethod
    def from_file(cls, config_path: Union[Path, str]) -> "Simulation":
        """
        Initializes a Simulation object from a YAML config file.

        Parameters
        ----------
        config_path : str or Path
            The path to the YAML file config file.

        Returns
        -------
        Simulation
            The initialized simulation object.
        """
        if not isinstance(config_path, Path):
            config_path = Path(config_path)

        print(f"config path loaded: {config_path}")  # Debugging output

        parser = ConfigParser(config_path)
        domain_data = parser.get_domain_data()
        if "boundaries" not in domain_data:
            raise KeyError("The 'boundaries' key is misising in configuration")
        
        grid_data = {
            "boundaries": domain_data["boundaries"],
            "step": domain_data["boundaries"]["step"]
        }
        print(f"DEBUG: Grid initialized with data -> {grid_data}")  # Debugging line

        grid = UniformGrid(boundaries=grid_data["boundaries"], step=grid_data["step"])

        timer = Timer(**parser.get_time_data())

        # # Ensure 'boundaries' exists
        # if "boundaries" not in domain_data:
        #     raise KeyError("The 'boundaries' key is missing in the configuration file. Check config.yml.")

        # boundaries = {"min": domain_data["boundaries"]["min"], "max": domain_data["boundaries"]["max"]}

        # grid = UniformGrid(boundaries, step=domain_data["step"])  # Corrected

        status_2d = parser.get_2d_status()
        drag = parser.get_drag_coefficient()

        number_of_neurites = parser.get_max_number_of_neurites()
        objects = ObjectFactory(**parser.get_objects_data())
        clocks = ClocksFactory(**parser.get_clocks_data())

        interactions_data = parser.get_interactions_data()
        interactions_type = interactions_data.pop("type")
        if interactions_type == "potentials":
            interactions = PotentialsFactory(**interactions_data)
        else:
            interactions = SimpleFactory(**interactions_data)
        plotter = Plotter()
        container = SimulationContainer(
            grid=grid,
            simulation_2d=status_2d,
            neuron_factory=NeuronFactory(number_of_neurites, objects, clocks),
            contact_factory=interactions,
            timer=timer,
            drag_coefficient=drag,
            plotter=Plotter() 
        )

        
        return cls(timer, container)


import yaml  # Ensure YAML is imported
from typing import Union

class ConfigParser:
    """Parses configuration files to load simulation parameters."""

    def __init__(self, config_path: Union[Path,str]):
        """Loads YAML config file into a dictionary."""
        with open(config_path, "r") as file:
            self.config = yaml.safe_load(file)

        print(f"DEBUG: Loaded YAML configuration")



    def get_domain_data(self):
        """Retrieves domain (grid) configuration from the YAML file and ensures 'step' is inside 'boundaries'."""
        
        # Load the domain section from the config file
        domain_data = self.config.get("domain", {})

        # Debugging: Print domain data
        print(f"DEBUG: domain_data -> {domain_data}")

        # Ensure 'boundaries' exists
        if "boundaries" not in domain_data:
            raise KeyError("The 'boundaries' key is missing in the configuration file. Check config.yml.")

        # Extract boundaries data
        boundaries = domain_data["boundaries"]

        # Ensure 'step' is inside 'boundaries'
        if "step" not in boundaries:
            boundaries["step"] = domain_data.get("step", 20.0)  # Move step inside boundaries if missing

        # Return the corrected structure
        return {"boundaries": boundaries}



    def get_time_data(self):
        """Retrieves simulation time settings."""
        return self.config.get("time", {"total_time": 1000, "step": 1})

    def get_2d_status(self):
        """Retrieves whether the simulation should run in 2D."""
        return self.config.get("simulation_2d", True)

    def get_drag_coefficient(self):
        """Retrieves drag coefficient settings."""
        return self.config.get("drag_coefficient", 10.0)

    def get_max_number_of_neurites(self):
        """Retrieves max neurites allowed per neuron."""
        return self.config.get("neurons", {}).get("max_number_of_neurites", 3)

    def get_objects_data(self):
        """Retrieves object properties."""

        objects_data = self.config.get("objects", {})

        return {
        "cell_radius": objects_data.get("cell_radius", 7.0),
        "cell_interaction_factor": objects_data.get("cell_interaction_factor", 1.0),
        "neurite_radius": objects_data.get("neurite_radius", 0.5),
        "neurite_interaction_factor": objects_data.get("neurite_interaction_factor", 0.8),
        "neurite_spring_constant": objects_data.get("neurite_spring_constant", 10.0),
        "neurite_default_length": objects_data.get("neurite_default_length", 20.0),
        }

    def get_clocks_data(self):
        """Retrieves clock properties for neuron proliferation, death, and differentiation rates."""
        clocks_data = self.config.get("clocks", {})

        return {
            "proliferation_rate": clocks_data.get("proliferation_rate", 1.5),  # Default: slow division
            "death_rate": clocks_data.get("death_rate", 0.0),  # Default: No death
            "differentiation_rate": clocks_data.get("differentiation_rate", 0.4),  # Default: slow differentiation
        }


    def get_interactions_data(self):
        """Retrieves interaction settings for neuron mechanics."""
        return self.config.get("interactions", {})
    
    def set(self, key: str, value):
        keys = key.split(".")
        config_section = self.config
        for k in keys[:-1]:
            config_section = config_section[k]
        config_section[keys[-1]] = value

    def save(self, config_path: Union[str, Path]):
        if not isinstance(config_path, Path):
            config_path = Path(config_path)
        with open(config_path, "w") as file:
            yaml.safe_dump(self.config, file)


# class ConfigParser:
#     def __init__(self, config_path: Union[str, Path]):
#         if not isinstance(config_path, Path):
#             config_path = Path(config_path)
#         with open(config_path, "r") as file:
#             self.config = yaml.safe_load(file)

#     def get_time_data(self):
#         return self.config["time"]

#     def get_domain_data(self):
#         return self.config["domain"]

#     def get_2d_status(self):
#         return self.config["domain"].get("use_2d", True)

#     def get_drag_coefficient(self):
#         return self.config["domain"].get("drag_coefficient", 10.0)

#     def get_max_number_of_neurites(self):
#         return self.config["neurons"].get("max_number_of_neurites", 3)

#     def get_objects_data(self):
#         return self.config["neurons"].get("objects", {})

#     def get_clocks_data(self):
#         return self.config["neurons"].get("clocks", {})

#     def get_interactions_data(self):
#         return self.config["interactions", {}]

    # def set(self, key: str, value):
    #     keys = key.split(".")
    #     config_section = self.config
    #     for k in keys[:-1]:
    #         config_section = config_section[k]
    #     config_section[keys[-1]] = value

    # def save(self, config_path: Union[str, Path]):
    #     if not isinstance(config_path, Path):
    #         config_path = Path(config_path)
    #     with open(config_path, "w") as file:
    #         yaml.safe_dump(self.config, file)

# Adjust configuration for testing rosette formation
CONFIG_PATH = r'C:\Users\16785\Desktop\neurorosette_code\config.yml'
parser = ConfigParser(CONFIG_PATH)
parser.set("neurons.clocks.proliferation_rate", 0.001)
parser.set("neurons.clocks.differentiation_rate", 0.001)
parser.set("interactions.sphere_sphere_adhesion", 10.0)
parser.set("time.total_time", 1000.0)  # Increased total simulation time
parser.save(CONFIG_PATH)

# Run simulation to validate indicator functionality
simulation = Simulation.from_file(CONFIG_PATH)
simulation.run()



   # def __init__(
    #     self,
    #     grid: UniformGrid,
    #     simulation_2d: bool,
    #     neuron_factory: NeuronFactory,
    #     contact_factory: ContactFactory,
    #     drag_coefficient: float = 10.0,
    #     density_check: Optional[CellDensityCheck] = None,
    # ) -> None:

    #     self.grid = grid
    #     self.simulation_2d = simulation_2d
    #     self.sphere_int = contact_factory.get_sphere_sphere_interactions()
    #     self.sphere_cylinder_int = contact_factory.get_sphere_cylinder_interactions()
    #     self.cylinder_int = contact_factory.get_cylinder_cylinder_interactions()
    #     self.neuron_factory = neuron_factory
    #     self.object_factory = self.neuron_factory.objects_factory
    #     self.drag_coefficient = drag_coefficient
    #     self.density_check = density_check
    #     self.animator = Animator()
    #     self.neurons = []

    #     if self.simulation_2d:
    #         self.animator.add_grid(
    #             self.grid.representation_grid_values,
    #             self.grid.representation_grid_values,
    #         )






